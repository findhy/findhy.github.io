
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Findhy's Blog</title>
  <meta name="author" content="Findhy">

  
  <meta name="description" content="大数据时代没有数据是玩不转的，真正拥有大数据的公司少之又少，更何况是个人开发者呢。数据有很多，最接近用户诉求、最能够精准定位用户需求的数据是最具有商业价值的，像搜索、电商、社交，而拥有这些数据的公司：Google、Facebook、百度、阿里巴巴、亚马逊等，它们首先会通过广告、 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://findhy.com">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Findhy's Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href='http://fonts.googleapis.com/css?family=Noto+Serif:400,700' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Findhy's Blog</a></h1>
  
    <h2>Art is long, Life is short.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  
  
</ul>

<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/05/big-data-open-source/">大数据 - 开放数据资源</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-05T20:43:54+08:00" pubdate data-updated="true">Jun 5<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>大数据时代没有数据是玩不转的，真正拥有大数据的公司少之又少，更何况是个人开发者呢。数据有很多，最接近用户诉求、最能够精准定位用户需求的数据是最具有商业价值的，像搜索、电商、社交，而拥有这些数据的公司：Google、Facebook、百度、阿里巴巴、亚马逊等，它们首先会通过广告、增值服务等形式来将数据变现，肯定不会将数据开放出来，而且未来数据会越来越成为一个公司的核心竞争力。</p>

<p>对于大数据研究人员或者创业者，我们有哪些数据可以使用呢？我简单整理了一下。</p>

<h3>1.数据分类</h3>

<p>我将数据分为两类：</p>

<ul>
<li>静态大数据（Batch Data）：通常是一个备份数据集，容量往往很大</li>
<li>动态流数据（Streaming Data）：这是实时变动的数据，数据不断的更新和涌入</li>
</ul>


<h3>2.数据来源</h3>

<h4>2.1 政府/非盈利机构（部分）</h4>

<p>国内：<br/>
<a href="http://www.stats.gov.cn/">http://www.stats.gov.cn/</a></p>

<p><a href="http://www.bosidata.com/">http://www.bosidata.com/</a></p>

<p><a href="http://www.cnnic.cn/">http://www.cnnic.cn/</a></p>

<p><a href="http://www.eguan.cn/">http://www.eguan.cn/</a></p>

<p>国外：<br/>
如果你在AWS上，这上面的可以看看，直接从S3 get下来。<br/>
<a href="http://aws.amazon.com/datasets">http://aws.amazon.com/datasets</a></p>

<p>freebase包含了很多开源项目的数据
<a href="https://developers.google.com/freebase/data">https://developers.google.com/freebase/data</a></p>

<p>这是一个很有商业价值的数据，包含互联网上所有的网页信息，相当于Google的数据
<a href="http://commoncrawl.org/data/">http://commoncrawl.org/data/</a></p>

<p>想做一些项目，Wikipedia的数据足够了，它既有Batch Data，也有Streaming Data。
<a href="http://en.wikipedia.org/wiki/Wikipedia:Database_download">http://en.wikipedia.org/wiki/Wikipedia:Database_download</a></p>

<h4>2.2 商业公司</h4>

<p>商业公司开放的数据通常都是有限制条件的，往往以一种合作的方式，而且基本上都是Streaming Data数据接口，案例有很多，像Twitter、腾讯、新浪微博，都有开放数据接口给个人开发者。<br/>
Twitter：<a href="https://dev.twitter.com/docs/api/1.1/post/statuses/filter">https://dev.twitter.com/docs/api/1.1/post/statuses/filter</a></p>

<p>腾讯：<a href="http://open.qq.com/">http://open.qq.com/</a></p>

<p>新浪微博：<a href="http://open.weibo.com/">http://open.weibo.com/</a></p>

<p>商业公司希望通过开放平台来构建一个以它为中心的生态系统，当然数据开放只是其中一部分。</p>

<h4>2.3 其它数据资源社区</h4>

<p>数据堂（主要是国内的政府机构数据）：<a href="http://www.datatang.com/">http://www.datatang.com/</a></p>

<p>本文整理参考：  <br/>
<a href="http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public">http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public</a></p>

<p><a href="http://www.datapanda.net/123/">http://www.datapanda.net/123/</a></p>

<p><a href="http://www.zhihu.com/question/19969760">http://www.zhihu.com/question/19969760</a></p>

<p class='post-footer'>
            original link:
            <a href='http://findhy.com/blog/2014/06/05/big-data-open-source/'>http://findhy.com/blog/2014/06/05/big-data-open-source/</a><br/>
            written by <a href='http://findhy.com'>Findhy</a>
            &nbsp;posted at <a href='http://findhy.com'>http://findhy.com</a>
            </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/05/s3cmd-config/">S3cmd 配置和使用</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-05T18:52:03+08:00" pubdate data-updated="true">Jun 5<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>s3cmd是AWS S3的命令行工具，可以用来下载、上传、同步文件，还可以配置权限。</p>

<h3>一、配置</h3>

<h4>1.安装python-pip</h4>

<pre><code>yum install python-pip
</code></pre>

<p>如果提示No package python-pip available，先安装<a href="http://dl.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm">epel-release-6-8.noarch.rpm</a></p>

<pre><code>rpm -ivh epel-release-6-8.noarch.rpm
</code></pre>

<h4>2.安装s3cmd</h4>

<pre><code>pip install s3cmd
</code></pre>

<h4>3.配置s3cmd</h4>

<pre><code>s3cmd --configure
</code></pre>

<p>分别输入Access Key和Secret Key</p>

<pre><code>Access Key:
Secret Key:
</code></pre>

<p>回车，如果提示：</p>

<pre><code>Encryption password is used to protect your files from reading
by unauthorized persons while in transfer to S3
Encryption password:
</code></pre>

<p>输入当前登录的操作系统用户</p>

<h4>4.HTTPS协议选择no</h4>

<pre><code>Use HTTPS protocol [No]: no
</code></pre>

<h4>5.代理不填直接回车</h4>

<pre><code>HTTP Proxy server name: 
</code></pre>

<h4>6.最后就是测试保存</h4>

<pre><code>Test access with supplied credentials? [Y/n] y
Save settings? [y/N] y
</code></pre>

<h4>7.测试</h4>

<pre><code>s3cmd ls
</code></pre>

<h4>8.下载整个目录</h4>

<pre><code>s3cmd get --recursive dir_name
</code></pre>

<h3>二、使用</h3>

<h4>1.查看所有的Buckets</h4>

<pre><code>s3cmd ls
</code></pre>

<h4>2.创建Buckets</h4>

<pre><code>s3cmd mb s3://my-bucket-name
</code></pre>

<h4>3.删除空Buckets</h4>

<pre><code>s3cmd rb s3://my-bucket-name
</code></pre>

<h4>4.上传</h4>

<pre><code>上传单个文件：s3cmd put file.txt s3://my-bucket-name/file.txt
批量上传：s3cmd put ./* s3://my-bucket-name/
上传整个目录：s3cmd put -r dir1 s3://my-bucket-name/
上传目录下所有文件：s3cmd put -r dir1/ s3://my-bucket-name/
</code></pre>

<h4>5.下载</h4>

<pre><code>下载单个文件：s3cmd get s3://my-bucket-name/file.txt file.txt
下载整个目录下的文件：s3cmd get -r  s3://my-bucket-name/bucket_dir ./
</code></pre>

<h4>6.删除文件</h4>

<pre><code>s3cmd del s3://my-bucket-name/file.txt
</code></pre>

<h4>7.查看空间大小</h4>

<pre><code>s3cmd du -H s3://my-bucket-name
</code></pre>

<h4>8.同步</h4>

<pre><code>同步当前目录下所有文件：s3cmd sync  ./  s3://my-bucket-name/
只列出不同步：s3cmd sync  --dry-run ./  s3://my-bucket-name/
同步且删除本地不存在的文件：s3cmd sync  --delete-removed ./  s3://my-bucket-name/
不检验跳过本地已经存在的文件：s3cmd sync  --skip-existing ./  s3://my-bucket-name/
排除包含文件规则：s3cmd sync --dry-run --exclude '*.txt' --include 'dir2/*' ./ 
更多参考这里：http://s3tools.org/s3cmd-sync
</code></pre>

<p class='post-footer'>
            original link:
            <a href='http://findhy.com/blog/2014/06/05/s3cmd-config/'>http://findhy.com/blog/2014/06/05/s3cmd-config/</a><br/>
            written by <a href='http://findhy.com'>Findhy</a>
            &nbsp;posted at <a href='http://findhy.com'>http://findhy.com</a>
            </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/04/swift/">Swift Introduction</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-04T09:51:16+08:00" pubdate data-updated="true">Jun 4<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Swift是Apple下一代开发语言，并且为了保证兼容性，Swift代码可以和Objective-C代码共存（官方解释是：New Swift code co-exists along side your existing Objective-C files in the same project）。下面介绍一下它的特性：</p>

<ul>
<li>并行（parallel）：it runs multiple programs concurrently as soon as their inputs are available, reducing the need for complex parallel programming</li>
<li>简单（easy）：Short, simple scripts can do large-scale work. The same script runs on multicore computers, clusters, grids, clouds, and supercomputers</li>
<li>快（fast）：it can run a million programs, thousands at a time, launching hundreds per second</li>
<li>灵活（flexible）：its being used in many fields of science, engineering, and business. Read the case studies</li>
</ul>


<p>官网：<a href="http://swift-lang.org/">http://swift-lang.org/</a><p class='post-footer'></p>

<pre><code>        original link:
        &lt;a href='http://findhy.com/blog/2014/06/04/swift/'&gt;http://findhy.com/blog/2014/06/04/swift/&lt;/a&gt;&lt;br/&gt;
        written by &lt;a href='http://findhy.com'&gt;Findhy&lt;/a&gt;
        &amp;nbsp;posted at &lt;a href='http://findhy.com'&gt;http://findhy.com&lt;/a&gt;
        &lt;/p&gt;
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/18/protocol-buffers/">Protocol Buffers vs Avro vs Thrift</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-18T15:53:37+08:00" pubdate data-updated="true">May 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>分布式架构一个重要的思路是解耦，将系统拆解为很多个相互独立的组件，每个组件通过接口对外提供服务，这种面向服务（SOA）架构设计可伸缩性更强、维护成本也更低。但服务的管理、分布式锁、高效的组件调用等相关技术复杂性也更高。本文介绍几个常用的高效的RPC框架。</p>

<h3>1.RPC模型</h3>

<p>一个简单的RPC调用模型如下图所示：<br/>
<img src="/images/rpc_1.png"></p>

<p>当我们在选型RPC框架的时候需要关注的几个核心问题是：</p>

<ul>
<li>传输的协议和数据（JSON、XML等）是什么？</li>
<li>如何高效的数据存储和传输？</li>
<li>服务器端处理请求的方式？</li>
</ul>


<h3>2.不建议的方案</h3>

<ul>
<li>SOAP：基于XML，传输的数据太多</li>
<li>CORBA：多度设计而且重量级，<a href="http://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture">http://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture</a></li>
<li>DCOM, COM+ :主要用于windows客户端程序</li>
<li>HTTP/JSON/XML/Plain Text：基于HTTP协议的，这种在简单的场景下是可以用的，像hessian，但缺点是缺乏更复杂的协议描述，只能传输简单的对象，而且JSON/XML都太重了</li>
</ul>


<h3>3.建议方案</h3>

<ul>
<li>Protocol Buffers</li>
<li>Apache Thrift</li>
<li>Apache Avro</li>
<li>Message Pack</li>
<li>kryo</li>
<li>BSON</li>
</ul>


<p>上面这些序列化框架共同的特点的是：有接口描述（IDL）、性能较高、版本控制和基于二进制的数据传输。下面重点介绍前三个。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/05/18/protocol-buffers/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/18/kafka/">Kafka Introduction</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-18T10:25:44+08:00" pubdate data-updated="true">May 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Kafka是Linkedin于2010开源的消息系统，现在已经放到Apache的项目中了，主页是：<a href="http://kafka.apache.org/%E3%80%82">http://kafka.apache.org/%E3%80%82</a>
Kafka是一个高吞吐量分布式的消息系统（publish-subscribe），它有如下这些特点：</p>

<ul>
<li>高性能：单个Kafka broker节点就可以处理来自数千个客户端数百MB的消息读取和写入。</li>
<li>可扩展：集群设计可以保证弹性扩展而不停机</li>
<li>持久化：消息被持久化到磁盘上，并且在集群内会有复制备份，所以不会有数据丢失。并且每一个broker可以处理TB级的消息而不影响性能</li>
<li>分布式：分布式集群设计保证了系统的健壮性和容错性</li>
</ul>


<h4>Kafka的部署结构图</h4>

<p><img src="/images/kafka.png"></p>

<h4>为什么要用Kafka</h4>

<ul>
<li>统一消息入口<br/>
Storm流数据平台需要处理的数据多种多样，如果直接用Storm来接入，会需要写很多的接口，这样必然不是最佳的解决方案，加了一层Kafka之后，Storm只需要处理来自Kafka的数据，由Kafka对接数据源。</li>
<li>消息持久化<br/>
直接用Storm或者其它MQ会发生数据丢失的可能，而Kafka是把数据持久化到磁盘上面而且会有复制备份，所以不会发生数据丢失。</li>
<li>支持分布式<br/>
支持分布式保证了架构的健壮性、弹性扩展和容错。</li>
</ul>


<p>Kafka在数据平台中的位置如图：<br/>
<img src="/images/kafka_hadoop.png"></p>

<p>Kafka作为消息中间件，为Storm提供数据来源。<br/>
Zookeeper为Kafka、Storm、HBase提供分布式协调服务，所以单独部署，不用HBase自带的Zookeeper。<br/>
HBase作为Storm的持久化层，也作为Titan的数据存储层。</p>

<p class='post-footer'>
            original link:
            <a href='http://findhy.com/blog/2014/05/18/kafka/'>http://findhy.com/blog/2014/05/18/kafka/</a><br/>
            written by <a href='http://findhy.com'>Findhy</a>
            &nbsp;posted at <a href='http://findhy.com'>http://findhy.com</a>
            </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/17/nginx-on-linux/">Nginx在Linux上的安装和配置</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-17T07:12:34+08:00" pubdate data-updated="true">May 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Nginx是一个高性能的HTTP和反向代理服务器，官网在<a href="http://nginx.org/">这里</a>。</p>

<h3>1.配置nginx的yum源</h3>

<pre><code>sudo vi /etc/yum.repos.d/nginx.repo
</code></pre>

<p>添加下面的内容：</p>

<pre><code>[nginx]
name=nginx repo 
baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ 
gpgcheck=0 
enabled=1
</code></pre>

<p>保存退出</p>

<h3>2.安装</h3>

<pre><code>sudo yum install nginx
</code></pre>

<h3>3.启动Nginx</h3>

<pre><code>sudo /etc/init.d/nginx start
</code></pre>

<p>访问：<a href="http://localhost">http://localhost</a></p>

<h3>4.其它命令</h3>

<pre><code>停止nginx服务：# /etc/init.d/nginx stop 
启动nginx服务：# /etc/init.d/nginx start 
编辑nginx配置文件：# vi /etc/nginx/nginx.conf
</code></pre>

<h3>5.反向代理配置</h3>

<pre><code>sudo vi /etc/nginx/nginx.conf
</code></pre>

<p>配置：</p>

<pre><code>upstream rexster {
    server 127.0.0.1:8182 weight=1 max_fails=1 fail_timeout=10s;
}

upstream yarn {
    server 127.0.0.1:8089 weight=1 max_fails=1 fail_timeout=10s;
}

upstream storm {
    server 127.0.0.1:7070 weight=1 max_fails=1 fail_timeout=10s;
}

server {
    listen 80;
    server_name yarn.xxx.com;
    location / {
        proxy_pass http://yarn;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    # redirect server error pages to the static page /50x.html
}
server {
    listen 80;
    server_name storm.xxx.com;
    location / {
        proxy_pass http://storm;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    # redirect server error pages to the static page /50x.html
}
</code></pre>

<p>输入域名测试，跳转成功</p>

<p class='post-footer'>
            original link:
            <a href='http://findhy.com/blog/2014/05/17/nginx-on-linux/'>http://findhy.com/blog/2014/05/17/nginx-on-linux/</a><br/>
            written by <a href='http://findhy.com'>Findhy</a>
            &nbsp;posted at <a href='http://findhy.com'>http://findhy.com</a>
            </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/17/storm-on-yarn/">Storm-on-YARN安装说明</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-17T06:37:52+08:00" pubdate data-updated="true">May 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Storm是一个流数据的实时计算框架，可以单独部署也可是部署在YARN上，本篇文章主要讲解Storm如何部署在YARN上面。  当然前提是Hadoop2.X已经装上了，然后需要安装Zookeeper来作为Storm集群的分布式协调服务。</p>

<p>环境说明</p>

<pre><code>master 10.0.1.252  
slave1 10.0.1.252  
slave2 10.0.1.252  
</code></pre>

<p>软件版本</p>

<pre><code>https://github.com/anfeng/storm-yarn/archive/master.zip  
Storm-0.9.0-win21  
zookeeper-3.4.5-cdh5.0.0-beta-2  
apache-maven-3.1.0  
</code></pre>

<h2>Zookeeper集群搭建</h2>

<hr />

<p>Storm需要使用zookeeper来协调整个集群，但是storm并不用zookeeper来传递消息，所以zookeeper的负载很低，大多数情况下，单个节点的zookeeper就够了，所以我们这里就只部署一台机子的zookeeper，后面再扩展到集群。</p>

<h3>1.安装JDK</h3>

<p>前面Hadoop集群已经安装了，只要保证JDK版本在1.6以上就可以了。</p>

<h3>2.下载和解压zookeeper安装包</h3>

<p>因为我们用的是CDH的Hadoop发行版，所以这里zookeeper也用CDH的，到这里下载：</p>

<pre><code>wget http://archive-primary.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.0.0-beta-2.tar.gz
</code></pre>

<p>解压</p>

<pre><code>tar –zxvf zookeeper-3.4.5-cdh5.0.0-beta-2.tar.gz
</code></pre>

<h3>3.修改zoo.cfg配置文件</h3>

<p>进入zookeeper安装目录/home/hadoop/zookeeper-3.4.5-cdh5.0.0-beta-2/conf，将zoo_sample.cfg重命名为zoo.cfg</p>

<pre><code>mv zoo_sample.cfg zoo.cfg
</code></pre>

<p>修改zoo.cfg文件，增加：</p>

<pre><code>tickTime=2000
dataDir=/home/hadoop/zookeeper-data
clientPort=2181
initLimit=5
syncLimit=2
server.1=master:2888:3888
</code></pre>

<p>创建这个目录：/home/hadoop/zookeeper-data</p>

<h3>4.修改myid</h3>

<p>在/home/hadoop/zookeeper-data目录下创建文件myid，里面内容为server的ID，这里写：1</p>

<h3>5.配置zookeeper的环境变量</h3>

<p>vi /etc/profile，增加：</p>

<pre><code>export ZOOKEEPER_HOME=/home/hadoop/zookeeper-3.4.5-cdh5.0.0-beta-2
export PATH=$PATH:$ZOOKEEPER_HOME/bin

source /etc/profile
</code></pre>

<h3>6.启动zookeeper</h3>

<pre><code>./bin/zkServer.sh start
</code></pre>

<h3>7.测试Zookeeper</h3>

<p>测试Zookeeper客户端是否可用</p>

<pre><code>./bin/zkCli.sh -server 127.0.0.1:2181
</code></pre>

<p>测试结果，看到进入到了zookeeper的命令行就是成功了：</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/05/17/storm-on-yarn/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/14/cdh5-hadoop-2-2-0-install/">Hadoop 2.2.0-cdh5.0.0-beta-2安装说明</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-14T23:08:37+08:00" pubdate data-updated="true">May 14<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>环境说明</p>

<pre><code>master 10.0.1.252  
slave1 10.0.1.252  
slave2 10.0.1.252  
</code></pre>

<p>软件版本</p>

<pre><code>Hadoop 2.2.0-cdh5.0.0-beta-2  
JDK 1.7.0_45
</code></pre>

<h2>开始安装</h2>

<hr />

<h3>1.创建用户</h3>

<pre><code>useradd hadoop
</code></pre>

<h3>2.修改密码</h3>

<pre><code>passwd hadoop
</code></pre>

<h3>3.修改HOSTS文件</h3>

<pre><code>10.0.1.252 master  
10.0.1.253 slave1  
10.0.1.254 slave2  
</code></pre>

<h3>4.节点互信配置</h3>

<p>在每个节点执行</p>

<pre><code>ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
cat ~/.ssh/id_dsa.pub &gt;~/.ssh/authorized_keys
</code></pre>

<p>更改权限</p>

<pre><code>[hadoop@master .ssh]$ chmod 600 authorized_keys
[hadoop@master ~]$ chmod 700 .ssh/
</code></pre>

<p>在master节点操作<br/>
拷贝其它节点的公钥到authorized_keys文件中</p>

<pre><code>[hadoop@master .ssh]$ ssh hadoop@slave1 cat ~/.ssh/authorized_keys &gt;&gt; authorized_keys
[hadoop@master .ssh]$ ssh hadoop@slave2 cat ~/.ssh/authorized_keys &gt;&gt; authorized_keys
</code></pre>

<p>然后将公钥拷贝到其它节点</p>

<pre><code>[hadoop@master .ssh]$ scp authorized_keys hadoop@slave1:~/.ssh/
[hadoop@master .ssh]$ scp authorized_keys hadoop@slave2:~/.ssh/
</code></pre>

<p>测试一下，不需要密码就可以访问</p>

<pre><code>ssh master  
Ssh slave1  
Ssh slave2  
</code></pre>

<p>首次会让输入yes，后面就可以直接登录了</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/05/14/cdh5-hadoop-2-2-0-install/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/05/14/titan-graph-db/">Titan图数据库介绍</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-14T22:35:18+08:00" pubdate data-updated="true">May 14<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Titan是一个高可用的分布式的图数据库，并且可以支撑上千个用户的并发事务，它有下面这些特性：</p>

<ul>
<li>弹性和性能的线性扩展</li>
<li>容错性</li>
<li>多数据中心的高可用性和热备份</li>
<li>支持事务的ACID和最终一致性</li>
<li>支持多种不同的后端存储<br/>
<em>Apache Cassandra（分布式）<br/>
Apache HBase（分布式）<br/>
Oracle BerkeleyDB（本地的）<br/>
Persistit（本地）</em></li>
<li>支持多种后端索引  <br/>
<em>ElasticSearch<br/>
Apache Lucene</em></li>
<li>与图形处理栈TinkerPop原生集成   <br/>
  <em>图查询语言Gremlin<br/>
  对象到图的映射器Frames<br/>
  图服务器Rexster<br/>
  标准图API：Blueprints</em></li>
<li>Apache2 license 开源协议</li>
</ul>


<p>Titan最大的优势在于其分布式和线性扩展，性能要高于Neo4j。还有支持HBase数据存储，这样可以和整个Hadoop平台完美结合起来，与YARN平台上面其它应用共享数据，但就这一点，以后Tian可能会代替Neo4j成为图数据库的主流。但是Titan目前应用还不是特别广泛，我们也是在尝试，最高版本是0.4，而且有很多需要改进的地方，包括与HBase的配置挺麻烦的，还无法放到YARN上来管理等等。</p>

<p>更多关于Titan的文档可以看<a href="https://github.com/thinkaurelius/titan/wiki">这里</a></p>

<p>可以从<a href="https://github.com/thinkaurelius/titan/wiki/Getting-Started">这里</a>开始</p>

<p class='post-footer'>
            original link:
            <a href='http://findhy.com/blog/2014/05/14/titan-graph-db/'>http://findhy.com/blog/2014/05/14/titan-graph-db/</a><br/>
            written by <a href='http://findhy.com'>Findhy</a>
            &nbsp;posted at <a href='http://findhy.com'>http://findhy.com</a>
            </p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/04/21/big-data-business/">大数据时代下的商机</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-04-21T22:57:30+08:00" pubdate data-updated="true">Apr 21<span>st</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>大数据时代下的我们有哪些商机？有哪些大数据产品可以参考？我没有数据怎么做？</p>

<blockquote><p>Q：<strong>大数据时代有哪些商业模式？</strong></p></blockquote>

<h3>数据租售</h3>

<p>直接卖数据API，代表公司有twitter。</p>

<h3>数据服务</h3>

<p>卖数据产品、数据分析结果，代表公司有BAT。这个是目前最流行也是最容易变现的模式，而且同样的数据可以打包成不同服务和产品出售，转化率很高，下面有例子，但是前提是你要有数据。</p>

<h3>数据技术</h3>

<p>提供大数据技术支持，代表公司有cloudera。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/04/21/big-data-business/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
   
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:findhy.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
  
    <section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/aws/'>AWS (1)</a></li>
<li class='category'><a href='/blog/categories/bigdata/'>Bigdata (1)</a></li>
<li class='category'><a href='/blog/categories/freedata/'>Freedata (1)</a></li>
<li class='category'><a href='/blog/categories/hadoop/'>Hadoop (2)</a></li>
<li class='category'><a href='/blog/categories/io/'>IO (1)</a></li>
<li class='category'><a href='/blog/categories/ios/'>IOS (1)</a></li>
<li class='category'><a href='/blog/categories/kafka/'>Kafka (1)</a></li>
<li class='category'><a href='/blog/categories/nginx/'>Nginx (1)</a></li>
<li class='category'><a href='/blog/categories/others/'>Others (2)</a></li>
<li class='category'><a href='/blog/categories/rpc/'>RPC (1)</a></li>
<li class='category'><a href='/blog/categories/reading/'>Reading (1)</a></li>
<li class='category'><a href='/blog/categories/storm/'>Storm (2)</a></li>
<li class='category'><a href='/blog/categories/titan/'>Titan (1)</a></li>
<li class='category'><a href='/blog/categories/yarn/'>YARN (1)</a></li>

  </ul>
</section><section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/06/05/big-data-open-source/">大数据 - 开放数据资源</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/05/s3cmd-config/">S3cmd 配置和使用</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/04/swift/">Swift Introduction</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/18/protocol-buffers/">Protocol Buffers vs Avro vs Thrift</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/18/kafka/">Kafka Introduction</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/17/nginx-on-linux/">Nginx在Linux上的安装和配置</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/17/storm-on-yarn/">Storm-on-YARN安装说明</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/14/cdh5-hadoop-2-2-0-install/">Hadoop 2.2.0-cdh5.0.0-beta-2安装说明</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/14/titan-graph-db/">Titan图数据库介绍</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/21/big-data-business/">大数据时代下的商机</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/17/storm/">Storm Introduction</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/23/how-do-design/">「写给大家的设计书」</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/20/the-hadoop-faq-for-oracle-dbas/">Oracle DBA如何转型到Hadoop平台</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/20/yarn/">YARN，Hadoop平台的操作系统</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/16/io/">存储系统-I/O</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/02/27/a-hackable-text-editor-for-the-21st-century/">A Hackable Text Editor for the 21st Century</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/02/24/how-to-become-a-hacker/">How to Become a Hacker</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Findhy -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'findhy';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>









<script>
  $(document).ready(function() {  
  var stickyNavTop = $('nav').offset().top;  
    
  var stickyNav = function(){  
  var scrollTop = $(window).scrollTop();  
         
  if (scrollTop > stickyNavTop) {   
      $('nav').addClass('sticky');  
  } else {  
      $('nav').removeClass('sticky');   
  }  
  };  
    
  stickyNav();  
    
  $(window).scroll(function() {  
      stickyNav();  
  });  
  });  
</script>


</body>
</html>

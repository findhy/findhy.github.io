<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Findhy's Blog]]></title>
  <link href="http://findhy.com/atom.xml" rel="self"/>
  <link href="http://findhy.com/"/>
  <updated>2014-06-23T16:14:21+08:00</updated>
  <id>http://findhy.com/</id>
  <author>
    <name><![CDATA[Findhy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Titan Visualization With VivaGraphJS]]></title>
    <link href="http://findhy.com/blog/2014/06/23/titan-visualization-with-vivagraphjs/"/>
    <updated>2014-06-23T16:09:23+08:00</updated>
    <id>http://findhy.com/blog/2014/06/23/titan-visualization-with-vivagraphjs</id>
    <content type="html"><![CDATA[<p><a href="http://findhy.com/blog/2014/06/21/graph-database-visualization/">上一篇文章</a>介绍了Graph Database的可视化技术方案，本项目是Titan的数据可视化和在线更新，前端使用的是<a href="https://github.com/anvaka/VivaGraphJS">VivaGraphJS</a>，在线更新就是调用Rexster提供的REST API，具体可以参考github上面的README介绍：<a href="https://github.com/titan-cn/titan-vivagraph">titan-vivagraph</a>。</p>

<!--more-->



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[存储性能瓶颈的成因、定位与排查]]></title>
    <link href="http://findhy.com/blog/2014/06/23/storage-performance-locate/"/>
    <updated>2014-06-23T10:41:46+08:00</updated>
    <id>http://findhy.com/blog/2014/06/23/storage-performance-locate</id>
    <content type="html"><![CDATA[<p>一个系统的性能瓶颈可能发生在很多地方，常见包括：CPU、内存、存储IO、网络、技术，其中存储IO的性能瓶颈最容易发生，往往我们刚开始搭建系统的时候都放在单台服务器上，当业务扩大后，单台已经无法支撑，常见的做法就是，前端加一个F5或者Nginx做负载均衡，后端应用做集群，数据库做集群或者读写分离、分表分库来缓解服务器的存储IO瓶颈，但是遇到存储瓶颈时我们如何定位问题和在架构设计的时候就去避免这样的问题呢，下面转载一篇EMC中文论坛的一篇文章，原文在这里<a href="https://community.emc.com/docs/DOC-34921">存储性能瓶颈的成因、定位与排查</a>。正文：</p>

<!--more-->


<h3>介绍</h3>

<p>企业数据存储性能瓶颈常常会发生在端口，控制器和磁盘，难点在于找出引起拥塞的单元，往往需要应用多重工具以及丰富的经验来查找并解决。
本文详细阐述存储瓶颈发生最常见的四种情况，可能发生的拥塞点，需要监控的参数指标，以及部署存储系统的最佳实践。</p>

<h3>更多信息</h3>

<h4>数据存储瓶颈的四个常见场景：</h4>

<p>以下是储瓶颈发生最常见的四种典型情况：</p>

<ol>
<li><p>当多个用户同时访问某一业务应用，无论是邮件服务器，企业资源规划（ERP）系统或数据库，数据请求会累积在队列中。单个I/O的响应时间开始增长，短暂延时开始转变成为漫长的等待。
这类响应时间敏感型应用的特征是，很多随机请求，读取比写入更多，I/O较小。最好的方法是：将负载分布在多块磁盘上，否则可能造成性能瓶颈。
如果应用增加了更多用户，或应用IOPS请求增加，则可能需要在RAID组中添加更多磁盘，或数据可能需要跨越更多磁盘，在更多层级做条带化。
存储在这样的情况下往往首先被怀疑，但大多数情况下并非存储引发，原因可能在于网络、应用或服务器。</p></li>
<li><p>带宽敏感型应用——如数据备份，视频流或安全登录，这类应用当多个用户同时访问大型文件或数据流时可能造成瓶颈。
定位这一问题存储管理员应当从备份服务器开始一路向下检查至磁盘，原因可能存在于这一通路的任何地方。
问题不一定发生在存储，可能是由于备份应用创建的方式或是磁带系统的工作方式引起的。如果瓶颈定位于存储，那么可能是由于服务I/O的磁盘数量不足，在控制器造成争用，或是阵列前端口带宽不足。
性能调优需要针对不同应用程序负载来完成。针对大型文件和流数据的调优并不适合于小型文件，反之亦然。这也就是为什么在大多数存储系统中往往做一个平衡，需要用户尝试并找出系统的折中。用户通常需要优化吞吐量或IOPS，但并不需要对两者同时优化。</p></li>
<li><p>RAID组中的磁盘故障。特别是在RAID 5中会造成性能的下降，因为系统需要重建校验数据。相比数据读写操作，重建会对性能造成更大影响。
即便坏盘是造成故障的根源，但控制器还是可能成为瓶颈，因为在重建过程中它需要不停地服务数据。当重建完成时，性能才会恢复正常。</p></li>
<li><p>部署了一种新的应用，而卷存在于处理繁忙邮件系统的同一磁盘。如果新的应用变得繁忙，邮件系统性能将会遭受影响。额外的流量最终会将磁盘完全覆盖。</p></li>
</ol>


<h4>存储瓶颈常发区域:</h4>

<h4>存储区域网络（Storage-area network, SAN）/阵列前端口</h4>

<p>存储部署于集中化SAN环境时，需考虑服务器和SAN之间的潜在网络瓶颈。例如，运行多部虚拟机的整合服务器可能不具备支持工作负载要求的足够网络端口。添加网络端口或转移网络密集型工作负载至其他服务器可解决这一问题。如前所述，对于带宽集中型应用，需考虑NFS有多少Fiber Channel 端口, or iSCSI 端口 or Ethernet 端口，需要用户站在带宽的角度来考量整个架构。</p>

<p>可能发生的问题包括：
如果阵列中端口数量不够，就会发生过饱和/过度使用。
虚拟服务器环境下的过量预定
端口间负载不均衡
交换机间链路争用/流量负荷过重
如某一HBA端口负载过重将导致HBA拥塞。使用虚拟机会导致问题更加严重。</p>

<h4>存储控制器</h4>

<p>一个标准的主动——被动或主动——主动控制器都有一个性能极限。接近这条上限取决于用户有多少块磁盘，因为每块磁盘的IOPS和吞吐量是固定的。</p>

<p>可能出现的问题包括：
控制器I/O过饱和，使得从缓存到阵列能够处理的IOPS受到限制
吞吐量“淹没“处理器
CPU过载/处理器功率不足
性能无法跟上SSD</p>

<h4>Cache</h4>

<p>由于服务器内存和CPU远比机械磁盘快得多，需为磁盘添加高速内存以缓存读写数据。例如，写入磁盘的数据存储在缓存中直到磁盘能够跟上，同时磁盘中的读数据放入缓存中直到能被主机读取。Cache比磁盘快1000倍，因此将数据写入和读出Cache对性能影响巨大。智能缓存算法能够预测你需要查找的数据，你是否会对此数据频繁访问，甚至是将访问频繁的随机数据放在缓存中。</p>

<p>可能发生的问题包括：
Cache memory不足
Cache写入过载，引起性能降低
频繁访问顺序性数据引起cache超负荷
Cache中需要持续不断地写入新数据，因此如果cache总是在refill，将无法从cache获益。</p>

<h4>磁盘</h4>

<p>磁盘瓶颈与磁盘转速有关, 慢速磁盘会引入较多延时。存储性能问题的排查首先考虑的因素就是磁盘速度，同时有多少块磁盘可进行并发读写。而另一因素是磁盘接口。采用更快的接口能够缓解磁盘瓶颈，但更重要的是在快速接口与相应更大的缓存大小以及转速之间取得平衡。同样，应避免将快速和慢速磁盘混入同一接口，因为慢速磁盘将会造成快速接口与快速磁盘的性能浪费。</p>

<p>可能引发的问题包括：
过多应用命中磁盘
磁盘数量不足以满足应用所需的IOPS或吞吐量
磁盘速度过慢无法满足性能需求及支持繁重工作负荷
Disk group往往是classic存储架构的潜在性能瓶颈，这种结构下RAID最多配置在16块磁盘。Thin结构通常每个LUN拥有更多磁盘，从而数据分布于更多spindle，因增加的并发性而减少了成为瓶颈的可能。</p>

<h4>需要监控的指标：</h4>

<p>曾经一度存储厂商们强调的是IOPS和吞吐量，但现在重点逐渐转变成为响应时间。也就是说，不是数据移动的速度有多快，而在于对请求的响应速度有多快。</p>

<p>正常情况下，15,000 rpm Fibre Channel磁盘响应时间为4ms，SAS磁盘响应时间约为5ms至6ms，SATA为10ms，而SSD少于1ms。如果发现Fibre Channel磁盘响应时间为12ms，或SSD响应时间变成5ms，那么就说明可能产生了争用，可能芯片发生了故障。</p>

<p>除了响应时间，其他需要监控的指标包括：
队列长度，队列中一次积累的请求数量，平均磁盘队列长度；
平均I/O大小千字节数；
IOPS （读和写，随机和顺序，整体平均IOPS）；
每秒百万字节吞吐量；
读写所占比例；
容量（空闲，使用和保留）。</p>

<h4>数据存储性能最佳实践：</h4>

<p>性能调优和改进的方式有很多种，用户当然可以通过添加磁盘，端口，多核处理器，内存来改善，但问题是：性价比，以及对业务是否实用。本文建议的方式是在预算范围内找寻性能最大化的解决方案。另外一个需要考虑的方面是环境并非一尘不变，系统部署方案要能够适应环境的改变需求。</p>

<p>首先需要考虑刷数据的性能特征，需要了解IO工作情况是怎样的。是否是cache友好型？是否是CPU集中型？业务数据很大数量很少，还是很小但数量很多？另外一方面就是构成存储环境的组件。包括应用，存储系统本身，网络。。。瓶颈可能在哪里，改善哪里最有效？</p>

<p>以下是一些常规建议：
不要仅仅根据空闲空间来分配存储，而需要结合考虑性能需求，确保为吞吐量或IOPS分配足够多的磁盘。
在磁盘间均衡分布应用负载，以减少热点地区的产生。
理解应用负载类型，并针对负载选择匹配的RAID类型。例如，写密集型应用建议使用RAID 1而不是RAID 5。因为当写入RAID 5时，需要计算校验位，需耗费较多时间。而RAID 1，写入两块磁盘速度快得多，无需计算。
磁盘类型（Fibre Channel, SAS, SATA）与期望性能相匹配。对于关键业务应用部署高性能磁盘，例如15,000 rpm Fibre Channel。
对于I/O密集型应用考虑采用SSD，但并不适用于写性能重要型应用。只要没有达到控制器瓶颈，SSD对读性能提升显著，但对写性能提升并没有明显效果。
采用端对端的监控工具，特别是虚拟服务器环境。虚拟端与物理端之间有一道防火墙，所以，需要穿透防火墙进行端到端的监控。
有些性能分析工具涵盖从应用到磁盘，有些仅局限于存储系统本身。由于性能是一个连锁反应包含很多变量，所以需要全面地分析数据。
以数据仅写入磁盘外部扇区的方式格式化磁盘。因减少数据定位时间而在高I/O环境下提升性能。负面作用是相当一部分磁盘容量未能得以使用。</p>

<h3>应用于</h3>

<p>存储性能分析、定位与排查</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[图数据库(graph Database)可视化]]></title>
    <link href="http://findhy.com/blog/2014/06/21/graph-database-visualization/"/>
    <updated>2014-06-21T11:04:58+08:00</updated>
    <id>http://findhy.com/blog/2014/06/21/graph-database-visualization</id>
    <content type="html"><![CDATA[<p>数据可视化是大数据的最后一环，重要性不可忽视，内行往往关心你的算法和架构，但是用户(客户或者领导)只会看最终展现在他们面前的东西，当然业务层面你需要先了解用户的核心需求，再去建模和设计指标，本文讨论关于数据可视化的技术方案，还有比较特别的图数据库的可视化。</p>

<!--more-->


<h3>1.可视化类型</h3>

<p>从用户响应时间的角度，有：</p>

<ul>
<li>静态可视化：当天日志导入到数据平台，晚上跑一些MR任务，再将执行结果存入HBase或者关系型数据库MySql，第二天运营看到结果</li>
<li>实时可视化：实时可视化前提是数据是实时变化的，通常用Storm或者Spark架构实时处理来自客户端或者Kafka的数据，再将处理完的数据导入到后台存储中，然后前端展现实时有两种方式，一种是被动的，就是你要再去刷新一次，这种比较好实现，一种是主动的，服务器端通知客户端，这种就用Websocket来做，如果服务器端用Node.js，更简单直接用socket.io</li>
</ul>


<p>从展现的图类型来看，可能列举不全：</p>

<ul>
<li>线性图：展现趋势</li>
<li>饼图/柱图：展现占比/对比</li>
<li>散点图：展现聚合关系</li>
<li>地理位置可视化：把数据在地图上展现，DataMap、GoogleMap都有接口，一般要求数据里面有地理位置属性（IP地址、城市、国家）</li>
<li>Graph：用Graph展现一个KnowledgeMap，像社交网站的关系图谱，通常用来做用户定位和推荐</li>
</ul>


<h3>2.前端可视化技术</h3>

<p>基于浏览器的开源的：</p>

<ul>
<li>highchart</li>
<li>d3.js</li>
<li>ECharts</li>
<li>google chart</li>
</ul>


<p>基于桌面的开源的：</p>

<ul>
<li><a href="https://gephi.org/">gephi</a></li>
</ul>


<p>上面这些比较常用，而且例子和社区都比较成熟，具体的可以直接去官方看，我们现在普通报表有用highchart和d3.js的，gephi也可以在浏览器端展现。</p>

<h3>3.Graph Database可视化</h3>

<p>关于Graph Database可视化单独拿出来，这块数据来源是像Titan、Neo4j和OrientDB这一类的图数据库，他们都提供基于REST的接口，以JSON数据返回Graph的信息，以Titan为例，在Titan上面可以搭建一个Rexster服务器，它提供很多针对Graph的REST接口，具体有哪些接口可以看这里<a href="https://github.com/tinkerpop/rexster/wiki/Basic-REST-API">Rexster-REST-API</a>，前端通过调用接口获取数据，在前端去构建Graph图，构建的方式可以是Canvas或SVG，关于这两的比较可以看这里<a href="http://msdn.microsoft.com/zh-cn/library/ie/gg193983(v=vs.85).aspx">SVG 与 Canvas：如何选择</a>。常用的技术解决方案有：</p>

<ul>
<li><a href="http://sigmajs.org/">Sigma.js</a>：开源，通用</li>
<li><a href="http://keylines.com/">Keylines</a>：商业方案，官网有针对Titan和Neo4j可视化的例子</li>
<li><a href="https://github.com/anvaka/VivaGraphJS">VivaGraph</a>：开源，通用，社区没有Sigma.js丰富</li>
<li><a href="https://github.com/anvaka/ngraph">ngraph</a>：VivaGraph的下一个版本，使用WebGL支持3d效果展现</li>
<li><a href="http://d3js.org/">D3.js</a>：开源，通用，上面提到了，它也提供Graph可视化的功能</li>
<li><a href="https://gephi.org/">Gephi</a>：开源，通用，很强大的基于桌面可视化解决方案，通过插件也可以在浏览器端展现</li>
<li><a href="http://linkurio.us/">Linkurious</a>：Neo4j专有的</li>
<li>Neo4J web-admin：Neo4j专有的</li>
</ul>


<p>参考：</p>

<p><a href="http://stackoverflow.com/questions/14867132/is-d3-js-the-right-choice-for-real-time-visualization-of-neo4j-graph-db-data/23522907#23522907">http://stackoverflow.com/questions/14867132/is-d3-js-the-right-choice-for-real-time-visualization-of-neo4j-graph-db-data/23522907#23522907</a></p>

<p><a href="http://stackoverflow.com/questions/18571685/neo4j-graph-visualizing-libraries?rq=1">http://stackoverflow.com/questions/18571685/neo4j-graph-visualizing-libraries?rq=1</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Titan Tutorial]]></title>
    <link href="http://findhy.com/blog/2014/06/19/titan-tutorial/"/>
    <updated>2014-06-19T13:43:40+08:00</updated>
    <id>http://findhy.com/blog/2014/06/19/titan-tutorial</id>
    <content type="html"><![CDATA[<p>Titan的<a href="https://github.com/thinkaurelius/titan/wiki">官方手册</a>内容更加丰富，但是太多，初学者不知如何下手，本文摘取重点部分，希望能快速上手Titan。</p>

<!--more-->


<h3>1.版本说明</h3>

<pre><code>Titan：titan-server-0.4.4
HBase：hbase-0.94.6-cdh4.3.2
Elasticsearch：elasticsearch-0.90.3
</code></pre>

<h3>2.环境说明</h3>

<p>服务器3台：</p>

<pre><code>master 10.0.1.252
slave1 10.0.1.253
slave2 10.0.1.254
</code></pre>

<p>HBase搭建的是集群，一个master，两个slave；Elasticsearch在master上部署的单机版本；Titan在master上部署的单机版本。本文不包括HBase集群搭建过程。</p>

<h3>3.Elasticsearch安装</h3>

<p>由于Titan0.4.4版本只能支持Elasticsearch的版本是0.90.3，看这里<a href="https://github.com/thinkaurelius/titan/wiki/Version-Compatibility">Version-Compatibility</a>。所以这里注意版本，Elasticsearch 0.90.3的文档可以看这里<a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/0.90/index.html">Elasticsearch-doc</a>。下面开始安装。</p>

<pre><code>wget https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-0.90.3.tar.gz
tar –zxvf elasticsearch-0.90.3.tar.gz
cd elasticsearch-0.90.3

启动elasticsearch：
./bin/elasticsearch
执行jps，会看到多了一个ElasticSearch的进程，说明成功
</code></pre>

<h3>4.Titan安装</h3>

<p>Titan有<a href="https://github.com/thinkaurelius/titan/wiki/Downloads">多种版本</a>提供下载，这里选择titan-server-0.4.4。</p>

<pre><code>mkdir /home/hadoop/titan-cdh4.3.2
进入
cd titan-cdh4.3.2
下载
wget http://s3.thinkaurelius.com/downloads/titan/titan-server-0.4.4.zip
解压
unzip titan-server-0.4.4.zip
进入目录
cd titan-server-0.4.4
</code></pre>

<p>修改配置文件</p>

<pre><code>vi ./conf/titan-hbase-es.properties

storage.hostname=master,slave1,slave2
storage.port=2181
cache.db-cache = true
cache.db-cache-clean-wait = 20
cache.db-cache-time = 180000
cache.db-cache-size = 0.5

storage.index.search.backend=elasticsearch
storage.index.search.hostname=master
storage.index.search.client-only=true
</code></pre>

<p>初始化Titan与HBase</p>

<pre><code>cd /home/hadoop/titan-cdh4.3.2/titan-server-0.4.4/
./bin/gremlin.sh

gremlin&gt;g = TitanFactory.open('conf/titan-hbase-es.properties')
</code></pre>

<p>这时候到hbase shell下面执行list命令，可以看到多了一张titan的表，执行describe &lsquo;titan&#8217;可以看到titan的表结构，加载数据：</p>

<pre><code>gremlin&gt; GraphOfTheGodsFactory.load(g)
</code></pre>

<p>到hbase shell下面执行scan &lsquo;titan&#8217;可以看到初始化了一些数据，下面用gremlin命令行验证一下这些数据</p>

<pre><code>gremlin&gt; saturn = g.V('name','saturn').next()
==&gt;v[4]
gremlin&gt; saturn.map()
==&gt;name=saturn
==&gt;age=10000
==&gt;type=titan
gremlin&gt; saturn.in('father').in('father').name
==&gt;hercules
</code></pre>

<p>如果输出一致则验证成功</p>

<h3>5.Rexster配置</h3>

<p>这部分文档参考：<a href="https://github.com/thinkaurelius/titan/wiki/Rexster-Graph-Server">https://github.com/thinkaurelius/titan/wiki/Rexster-Graph-Server</a></p>

<p>修改rexster配置文件</p>

<pre><code>cd /home/hadoop/titan-cdh4.3.2/titan-server-0.4.4/conf
cp rexster-cassandra-es.xml rexster-hbase-es.xml
vi rexster-hbase-es.xml
</code></pre>

<p>有两个地方要改，一个是http这个标签，一个是graphs这个标签，黄色是需要修改的内容，第一个修改如下：</p>

<pre><code>&lt;http&gt;
  &lt;server-port&gt;8182&lt;/rexster-server-port&gt;
  &lt;base-uri&gt;http://54.255.164.52&lt;/base-uri&gt;
  &lt;web-root&gt;public&lt;/web-root&gt;
  &lt;character-set&gt;UTF-8&lt;/character-set&gt;
  ...
&lt;/http&gt;
</code></pre>

<p>第二个修改如下：</p>

<pre><code>&lt;graphs&gt;
    &lt;graph&gt;
        &lt;graph-name&gt;graph&lt;/graph-name&gt;
       &lt;graph-type&gt;com.thinkaurelius.titan.tinkerpop.rexster.TitanGraphConfiguration&lt;/graph-type&gt;
        &lt;!-- &lt;graph-location&gt;/tmp/titan&lt;/graph-location&gt; --&gt;
        &lt;graph-read-only&gt;false&lt;/graph-read-only&gt;
        &lt;properties&gt;
            &lt;storage.backend&gt;hbase&lt;/storage.backend&gt;
            &lt;storage.hostname&gt;master,slave1,slave2&lt;/storage.hostname&gt;
            &lt;storage.index.search.backend&gt;elasticsearch&lt;/storage.index.search.backend&gt;
            &lt;storage.index.search.hostname&gt;master&lt;/storage.index.search.hostname&gt;
            &lt;!--&lt;storage.index.search.directory&gt;../db/es&lt;/storage.index.search.directory&gt;--&gt;
            &lt;storage.index.search.client-only&gt;false&lt;/storage.index.search.client-only&gt;
            &lt;storage.index.search.local-mode&gt;false&lt;/storage.index.search.local-mode&gt;
        &lt;/properties&gt;
        &lt;extensions&gt;
          &lt;allows&gt;
            &lt;allow&gt;tp:gremlin&lt;/allow&gt;
          &lt;/allows&gt;
        &lt;/extensions&gt;
    &lt;/graph&gt;
&lt;/graphs&gt;
</code></pre>

<p>启动Rexster</p>

<pre><code>cd /home/hadoop/titan-cdh4.3.2/titan-server-0.4.4
./bin/rexster.sh –s –c ../conf/rexster-hbase-es.xml
</code></pre>

<p>访问<a href="http://master-ip:8182/">http://master-ip:8182/</a></p>

<p>出现下面画面则启动成功</p>

<p><img src="http://findhy.com/images/titan-tul-1.png"></p>

<p><a href="https://github.com/tinkerpop/rexster/wiki">Rexster</a>是建立在任何实现了Blueprints的图数据库(Graph Database)之上的web server，它提供这三种功能：</p>

<ul>
<li>提供基于REST的接口方法：GET, POST, PUT, and DELETE，去操作Graph Database

<ul>
<li>基于上面的例子，在浏览器输入：<a href="http://master-ip:8182/graphs/graph/edges">http://master-ip:8182/graphs/graph/edges</a>  会返回graph的edge信息</li>
</ul>
</li>
<li><a href="https://github.com/tinkerpop/rexster/wiki/The-Dog-House">The Dog House</a>提供基于浏览器去操作Graph，还有可视化Graph，界面如下：

<ul>
<li><img src="http://findhy.com/images/titan-tul-2.png"></li>
<li><img src="http://findhy.com/images/titan-tul-3.png"></li>
</ul>
</li>
<li>提供<a href="https://github.com/tinkerpop/rexster/wiki/RexPro-Java">RexsterClient</a>客户端去访问Rexster server，包括执行一些Graph的操作</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Titan经典入门PPT]]></title>
    <link href="http://findhy.com/blog/2014/06/19/titan-classic-get-started/"/>
    <updated>2014-06-19T11:00:50+08:00</updated>
    <id>http://findhy.com/blog/2014/06/19/titan-classic-get-started</id>
    <content type="html"><![CDATA[<p>下面是Marko Rodriguez分享的一个PPT，原文在这里<a href="http://www.slideshare.net/slidarko/titan-the-rise-of-big-graph-data">slideshare.</a>，该PPT深入浅出，从Graph基础知识到Graph Database到Titan的优势，还包括基本的入门操作，我觉得非常经典，很适合初学者，在此分享，因为原文PPT表达很简单而且加上动画展示，所以即使英文不好的人看也没有障碍。</p>

<!--more-->




<iframe src="http://www.slideshare.net/slideshow/embed_code/13328271 " width="595" height="446" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen></iframe>


<p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[怎么在Octopress Blog中嵌入slideshare]]></title>
    <link href="http://findhy.com/blog/2014/06/19/how-to-put-slideshare-on-octopress-blog/"/>
    <updated>2014-06-19T10:56:50+08:00</updated>
    <id>http://findhy.com/blog/2014/06/19/how-to-put-slideshare-on-octopress-blog</id>
    <content type="html"><![CDATA[<p>怎么在Octopress blog中嵌入slideshar，使用该插件<a href="https://github.com/petehamilton/Octopress-Slideshare-Plugin">Octopress-Slideshare-Plugin</a>，下面是操作过程。</p>

<!--more-->


<h3>1.下载插件</h3>

<pre><code>git clone https://github.com/petehamilton/Octopress-Slideshare-Plugin.git
</code></pre>

<h3>2.安装插件</h3>

<p>进入上面下载的插件目录，拷贝Octopress-Slideshare-Plugin/slideshare.rb到octopress/plugins目录下面</p>

<h3>3.生成对应的Slideshare Embed ID</h3>

<p>到<a href="http://www.slideshare.net/">slideshare</a>网站找到你需要嵌入的ppt。</p>

<p><img src="http://findhy.com/images/slideshare-1.png"></p>

<p>点击Embed，生成类似下面的链接，最后的291600就是我们要的Slideshare Embed ID</p>

<pre><code>http://www.slideshare.net/slideshow/embed_code/291600
</code></pre>

<h3>4.嵌入</h3>

<p>在你的bolg MD文件中添加下面的代码：</p>

<p><img src="http://findhy.com/images/slideshare-2.png"></p>

<p>执行</p>

<pre><code>rake generate
rake preview
</code></pre>

<p>看到</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/291600 " width="595" height="446" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen></iframe>


<p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TinkerPop]]></title>
    <link href="http://findhy.com/blog/2014/06/18/tinkerpop/"/>
    <updated>2014-06-18T15:09:59+08:00</updated>
    <id>http://findhy.com/blog/2014/06/18/tinkerpop</id>
    <content type="html"><![CDATA[<p><a href="http://www.tinkerpop.com/">TinkerPop</a>是Graph领域的一系列开源工具包的集合。下面分别介绍：</p>

<!--more-->


<h3>Blueprints</h3>

<p>上一篇文章我们讲<a href="http://findhy.com/blog/2014/06/17/graph-database-data-structure/">Graph Database理论知识</a>的时候，提到了图论关于图(Graph)的定义：顶点和边组成的图形，也在后面提到了关于Graph的一系列操作，包括：插入顶点、插入边、获取路径等等。Blueprints是对图这种抽象模型的具体实现，官方定义：<a href="https://github.com/tinkerpop/blueprints/wiki">Blueprints</a>是一系列<a href="https://github.com/tinkerpop/gremlin/wiki/Defining-a-Property-Graph">属性图模型接口(property graph model interface)</a>，那么接下来，什么是属性图模型(property graph model)？满足下面三个条件的图(Graph)被称为属性图(property graphs)：</p>

<ul>
<li>顶点(vertices)和边(edges)可以包含任意多的key/value的属性</li>
<li>方向性，边(edges)具有方向性，可以从一个顶点(vertices)指向另外一个顶点(vertices)</li>
<li>多样性，顶点(vertices)之间的关系边(edges)可以是不同的类型，就是说两个顶点(vertices)可以拥有多种不同类型的边(edges)</li>
</ul>


<p>满足上述三个条件的graph被称为property graphs，下面展现一个property graphs的例子，数据格式可以是<a href="http://graphml.graphdrawing.org/index.html">GraphML</a>或者<a href="https://github.com/tinkerpop/blueprints/wiki/GraphSON-Reader-and-Writer-Library">GraphSON</a>，前者是<a href="https://github.com/tinkerpop/gremlin/blob/master/data/graph-example-1.xml">XML</a>，后者<a href="https://github.com/tinkerpop/gremlin/blob/master/data/graph-example-1.json">JSON</a>，当然JSON会更轻量级。</p>

<p><img src="http://findhy.com/images/tinkpop-1.png"></p>

<p>一个property graphs包含下面这些元素</p>

<ul>
<li>一系列顶点(vertices)

<ul>
<li>每一个顶点(vertex)有一个唯一标识</li>
<li>每一个顶点(vertex)有一个或者多个指向其它顶点的边(edge)</li>
<li>每一个顶点(vertex)有一个或者多个指向自己的边(edge)</li>
<li>每一个顶点(vertex)包含了一个或多个由map定义的key/value属性</li>
</ul>
</li>
<li>一系列边(edges)

<ul>
<li>每一个边(edge)有一个唯一标识</li>
<li>每一个边(edge)具有方向性指向一个顶点(vertex)</li>
<li>每一个边(edge)有一个label来标识两个顶点(vertex)之间的关系</li>
<li>每一个边(edge)包含了一个或多个由map定义的key/value属性</li>
</ul>
</li>
</ul>


<p>什么是property graphs搞明白之后，我们再来看Blueprints，Blueprints为属性图模型(property graph data model)提供了一套接口、实现还有测试用例，你可以把它想象成JDBC，JDBC对数据库的操作原语进行了封装和实现，只不过JDBC是用来操作关系型数据库，而Blueprints用来操作Graph Database。现在主流的Graph Database都支持Blueprints，而且在TinkerPop整个软件栈中，Blueprints是最底层的基础，就是其它的工具包都是基于它之上的封装和扩展。怎么使用Blueprints？</p>

<p>maven引入：</p>

<pre><code>&lt;dependency&gt;
   &lt;groupId&gt;com.tinkerpop.blueprints&lt;/groupId&gt;
   &lt;artifactId&gt;blueprints-core&lt;/artifactId&gt;
   &lt;version&gt;2.5.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>

<p>样例代码：</p>

<pre><code>Graph graph = new Neo4jGraph("/tmp/my_graph");
Vertex a = graph.addVertex(null);
Vertex b = graph.addVertex(null);
a.setProperty("name","marko");
b.setProperty("name","peter");
Edge e = graph.addEdge(null, a, b, "knows");
e.setProperty("since", 2006);
graph.shutdown();
</code></pre>

<h3>Pipes</h3>

<p><a href="https://github.com/tinkerpop/pipes/wiki">Pipes</a>是一个图数据处理的框架，可以将它理解为管道(Pipe),它最大的好处是管道(Pipe)的输出可以作为其它管道(Pipe)的输入，这样我们就可以实现类似于mapreducer的复杂运算。</p>

<h3>Gremlin</h3>

<p><a href="https://github.com/tinkerpop/gremlin/wiki">Gremlin</a>是一个图遍历语言，可以用Gremlin来实现图的查询、分析和操作，Gremlin只能适用于支持Blueprints的图数据库，支持多种JVM语言：Java 和 Groovy，文档：<a href="http://gremlindocs.com/">GremlinDocs</a>、<a href="http://sql2gremlin.com/">SQL2Gremlin</a>。</p>

<h3>Frames</h3>

<p><a href="https://github.com/tinkerpop/frames/wiki">Frames</a>是一个object-to-graph映射框架</p>

<h3>Furnace</h3>

<p><a href="https://github.com/tinkerpop/furnace/wiki">Furnace</a>是一个Graph算法包</p>

<h3>Rexster</h3>

<p><a href="https://github.com/tinkerpop/rexster/wiki">Rexster</a>是一个Graph Server</p>

<p>TinkerPop的维护人员来自不同的Graph Database产品厂商，像Neo4j、Titan、OrientDB、Bitsy，它在Graph Database领域的地位我理解就像JavaEE里面的Apache。在最新的<a href="https://github.com/tinkerpop/tinkerpop3">TinkerPop3.0</a>版本的时候，TinkerPop将原本分散的各个工具包合并成了一个项目，并且增加了很多特性，Titan0.5版本还不支持TP3，将会在Titan1.0版本时支持，更多的可以看<a href="http://www.tinkerpop.com/docs/current/">TinkerPop3 Story/doc</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Graph Database]]></title>
    <link href="http://findhy.com/blog/2014/06/17/graph-database-data-structure/"/>
    <updated>2014-06-17T14:50:02+08:00</updated>
    <id>http://findhy.com/blog/2014/06/17/graph-database-data-structure</id>
    <content type="html"><![CDATA[<p><a href="http://en.wikipedia.org/wiki/Graph_database">Graph database</a>是近年兴起的NoSQL存储模型(graph, key-value, column, and document)中的一种实现数据库，代表产品是Neo4j、Titan，它的理论基础是<a href="http://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA">图论/Graph theory</a>,一个数学分支，主要研究顶点和边组成的图形的数学理论和方法，它的起源也比较有意思，这部分本文不谈，感兴趣的同学可以去Google研究一下。</p>

<!--more-->


<p>想了解Graph Database，我们还是要把图论(Graph theory)简单说一下，略过中间复杂的数学问题，我们以结果为导向，图论可以解决哪些问题？这里有一个<a href="http://www.global-sci.org/mc/issues/3/no2/freepdf/67s.pdf">图论经典问题简介</a>,诸如<a href="http://zh.wikipedia.org/wiki/%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%98">最短路径问题</a>、<a href="http://zh.wikipedia.org/wiki/%E6%97%85%E8%A1%8C%E6%8E%A8%E9%94%80%E5%91%98%E9%97%AE%E9%A2%98">旅行售货商问题</a>、<a href="http://zh.wikipedia.org/wiki/%E9%82%AE%E9%80%92%E5%91%98%E9%97%AE%E9%A2%98">中国邮递员问题</a>，这些是图论中研究的经典问题，具体实现会涉及到不同的算法问题。</p>

<p>举个例子，在社交网络中，你搜索了一个人，怎么最快结识他，这其实就是一个最短路径问题，LinkedIn已经有相关的推荐产品，可以去试一下。而且未来随着智能设备的普及个人数据会呈现爆炸性增长，就是人的属性和关联会更多更复杂，其实这个问题在阿里现在已经存在了，他收购了那么多产品，重要一点就是为了获取数据，现在阿里拥有一个人的网购数据(淘宝、天猫)、社交数据(陌陌、新浪微博)、浏览搜索数据(UC、优酷)等等，这么庞大的一个数据结构该怎么来描述，更关键的是怎么快速的去做定位和推荐，这也是Graph Database兴起的一个原因，未来Graph这块必然会大放异彩。</p>

<h3>数据结构</h3>

<p>Graph Database的存储单元是：节点(nodes)、关系/边(edges)、属性(properties)<br/>
<img src="http://findhy.com/images/GraphDatabase_1.png"></p>

<ul>
<li>节点(nodes)：通常是一个实体，类似于社交网络中的人或者电商网络中的商品，节点不一定都是同一个类型的，比如我们构建一个Graph，节点是人和商品，之间的连接是谁买了哪个商品，这样我们可以很容易找到买相同的产品的人，去做关联推荐</li>
<li>属性(properties)：是与节点(nodes)相关的信息，通常是节点的描述，比如人的性别、年龄、地点、电话等信息</li>
<li>关系/边(edges)：用来连接节点(nodes)的，代表节点(nodes)与节点(nodes)之间具有某种关系，比如用户A和用户B是好友，用户A和用户C来自同一个地方，关系可以是有方向和无方向的，而且节点(nodes)之间可以有多条关系</li>
</ul>


<p>Graph Database的数据结构使得它在处理数据关联问题更具优势，因为它的节点(nodes)原生的就是通过某种关系连接在一起，这样就减少了join这样耗费资源的操作。</p>

<h3>算法</h3>

<p>Graph Database中很多问题都涉及到一些重要算法，下面列举一些，数据来源<a href="http://zh.wikipedia.org/wiki/%E6%9C%80%E7%9F%AD%E8%B7%AF%E9%97%AE%E9%A2%98">Wikipedia-Graph-Algorithms</a>：</p>

<ul>
<li>基本遍历：深度优先搜索、广度优先搜索、A*、Flood fill</li>
<li>最短路径：Dijkstra、Bellman-Ford、Floyd-Warshall 、Kneser图</li>
<li>最小生成树：Prim、Kruskal</li>
<li>强连通分量：Kosaraju算法、Gabow算法、Tarjan算法</li>
<li>图匹配：匈牙利算法、Hopcroft–Karp、Edmonds&rsquo;s matching</li>
<li>网络流：Ford-Fulkerson、Edmonds-Karp、Dinic 、Push-relabel maximum flow</li>
</ul>


<h3>常规操作</h3>

<p>类似于关系型数据库提供的CRUD操作，Graph Database也提供一系列指令来操作Graph，下面G代表一个Graph data structure，你可以把它想象为关系型数据库中的一张表。</p>

<ul>
<li>adjacent(G, x, y)：检查节点x和节点y之间是否有一个边(edge)</li>
<li>neighbors(G, x)：列出所有与节点x有连接/边(edge)的节点</li>
<li>add(G, x, y)：插入一个边(edge)，从x指向y</li>
<li>delete(G, x, y)：删除一个从x指向y的边(edge)</li>
<li>get_node_value(G, x)：返回节点x的相关属性</li>
<li>set_node_value(G, x, a)：设置节点x的属性为a</li>
<li>get_edge_value(G, x, y)：返回节点x和y之间的边(edge)的属性，边(edge)也是有属性的</li>
<li>set_edge_value(G, x, y, v)：设置节点x和y之间的边(edge)的属性为v</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Titan:下一代分布式图数据库]]></title>
    <link href="http://findhy.com/blog/2014/06/17/titan-next-generation-graph-database/"/>
    <updated>2014-06-17T10:23:30+08:00</updated>
    <id>http://findhy.com/blog/2014/06/17/titan-next-generation-graph-database</id>
    <content type="html"><![CDATA[<p><a href="http://thinkaurelius.github.io/titan/">Titan</a>是一个由<a href="http://thinkaurelius.com/">Aurelius</a>维护的开源协议为<a href="http://www.apache.org/licenses/LICENSE-2.0.html">Apache 2.0</a>的分布式图形数据库。</p>

<!--more-->


<p>Graph Database作为NoSQL数据库四种存储模式(graph, key-value, column, and document)的其中一种，近年来发展迅猛，因为随着人工智能和社交网络不断发展和融合，数据结构越来越复杂，举个例子，以用户为中心的模型，用户的相关数据可能来源他的社交网络，也可能来源他的网购记录，也可能来源他的个人可穿戴设备等等，这个数据会呈现爆炸性增长，如果用户基数为千万级，再去做关联和流行度分析会非常复杂，Graph Database处理这样的需求具体天生的优势。目前市面上的<a href="http://en.wikipedia.org/wiki/Graph_database#Graph_database_projects">Graph Database</a>有很多，<a href="http://www.neo4j.org/">Neo4j</a>是最为成熟和知名度最高的产品，但因为Neo4j<a href="http://stackoverflow.com/questions/21558589/neo4j-sharding-aspect/21566766#21566766">不支持分片</a>导致其存在可伸缩性的问题，但是貌似Neo4j已经推出相应的解决方案架构，参考这里<a href="http://info.neotechnology.com/rs/neotechnology/images/Understanding%20Neo4j%20Scalability(2).pdf">Neo4j HA-1</a>、<a href="http://neo4j.com/blog/2013-whats-coming-next-in-neo4j/">Neo4j HA-2</a>。</p>

<p>Titan作为新一代的Graph Database，还比较年轻，但非常有前途，它的优势有几方面：</p>

<ul>
<li>天生支持分布式：横向扩展很容易，并且性能可以线性增长</li>
<li>性能：Titan官方在Titan-0.1-alpha做过一个<a href="http://thinkaurelius.com/2012/08/06/titan-provides-real-time-big-graph-data/">测试</a>，性能表现非常强劲</li>
<li>后端存储无关：它可以将数据存储在不同的数据库，目前支持HBase、Cassandra和BerkeleyDB，而且Titan 0.5.0将会集成另外一个模块：Titan/Hadoop，这样会让Titan与现有的数据平台结合更加容易</li>
<li>后端索引无关：目前支持<a href="http://www.elasticsearch.org/">ElasticSearch</a>和<a href="http://lucene.apache.org/">Apache Lucene</a>两种索引</li>
<li>支持多数据中心的高可用和热备份</li>
<li>原生支持<a href="http://www.tinkerpop.com/">tinkerpop</a>：<a href="http://www.tinkerpop.com/">tinkerpop</a>是一系列Graph领域的开源软件栈</li>
</ul>


<p>Titan的架构图：<br/>
<img src="http://findhy.com/images/titan-next-1.png"></p>

<h4>总结</h4>

<p>目前Titan刚刚发布<a href="https://groups.google.com/forum/#!topic/aureliusgraphs/cNb4fKoe95M">Titan 0.5.0-M1</a>版本，增加了很多特性，而且文档更加完善了，Titan 0.5.0 GA会在七月底发布，这会是一个非常接近1.0版本的产品，对于有需求的公司可以进行预研，对它完全掌握了再投入生产，毕竟Titan在实际生产环境的案例和技术文档都比较欠缺。但我相信Titan会成为下一代非常出色的Graph Database，我也会继续研究Titan和发布相关Titan相关的文章，希望能为Titan在中国推广做一些贡献，有感兴趣的同学欢迎一起讨论。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storm与Kafka集成开发]]></title>
    <link href="http://findhy.com/blog/2014/06/16/storm-kafka-dev/"/>
    <updated>2014-06-16T16:44:35+08:00</updated>
    <id>http://findhy.com/blog/2014/06/16/storm-kafka-dev</id>
    <content type="html"><![CDATA[<p>项目源码在这里<a href="https://github.com/findhy/storm-kafka">storm-kafka</a>，里面包括了简单说明和测试过程，照着做就可以了，下面简单介绍一下。</p>

<p><img src="http://findhy.com/images/storm-kafka-dev1.png"></p>

<!--more-->


<ul>
<li>数据源：该架构主要用来处理Streaming data，例子使用Wikipedia提供的Websocket接口，实时发送当前在Wikipedia网站编辑内容的用户相关信息</li>
<li>Websocket：可以参考这篇文章<a href="http://findhy.com/blog/2014/06/12/java-websocket/">Java-Websocket</a>，本框架使用Java语言作为kafka的客户端实现，所以也用的Java来实现Websocket，Kafka也支持其它语言作为client，这里是支持的客户端列表<a href="https://cwiki.apache.org/confluence/display/KAFKA/Clients">kafka-client</a>，用Node.js也是一个不错的选择</li>
<li>Storm：Storm与Kafka集成的重点在于Storm的Spout部分，这部分直接依赖这个库<a href="https://github.com/wurstmeister/storm-kafka-0.8-plus">storm-kafka-0.8-plus</a>，实现订阅Kafka的Topic</li>
<li>数据出口：Storm对Streaming data处理完了之后，一般会有两种出口，一是将数据持久化到HBase/Cassandra/Redis这样的NoSql Database中，二是通知前端在可视化界面上实时变动，该框架实现的是Storm将处理完的数据再次发送到Kafka中，前端通过Node.js和socket.io去订阅这个数据就可以(这部分暂未实现)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Caused by: java.io.NotSerializableException: kafka.javaapi.producer.Producer]]></title>
    <link href="http://findhy.com/blog/2014/06/14/kafka-storm-notserializableexception/"/>
    <updated>2014-06-14T20:24:15+08:00</updated>
    <id>http://findhy.com/blog/2014/06/14/kafka-storm-notserializableexception</id>
    <content type="html"><![CDATA[<p>我们现在的架构使用Kafka作为消息的入口，数据全部发送到Kafka中，然后用Storm的Topology写一个spout去订阅Kafka的消息，执行提交Topology：</p>

<!--more-->


<pre><code>storm jar storm-kafka-0.8-plus-test-0.1.0-SNAPSHOT-jar-with-dependencies.jar storm.kafka.topology.CyouStormTopology -c nimbus.host=10.0.1.254
</code></pre>

<p>但是报错：</p>

<pre><code>Exception in thread "main" java.lang.RuntimeException: java.io.NotSerializableException: kafka.javaapi.producer.Producer
    at backtype.storm.utils.Utils.serialize(Utils.java:56)
    at backtype.storm.topology.TopologyBuilder.createTopology(TopologyBuilder.java:89)
    at storm.kafka.topology.CyouStormTopology.main(CyouStormTopology.java:32)
Caused by: java.io.NotSerializableException: kafka.javaapi.producer.Producer
    at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1183)
    at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
    at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
    at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
    at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
    at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
    at backtype.storm.utils.Utils.serialize(Utils.java:52)
    ... 2 more
</code></pre>

<p>后来参考这里的提示：<a href="https://groups.google.com/forum/#!msg/storm-user/heQSeawhC5I/y40-FnQ4hiUJ  ">https://groups.google.com/forum/#!msg/storm-user/heQSeawhC5I/y40-FnQ4hiUJ  </a>
修改代码如下：</p>

<pre><code>    @Override
    public void prepare(Map stormConf, TopologyContext context,
            OutputCollector collector) {
        LOG.info("begin to prepare in bolt from CyouSendToKafkaBolt");
        this._collerctor = collector;

        Properties props = new Properties();
        props.put("metadata.broker.list", "master:9092");
        props.put("serializer.class", "kafka.serializer.StringEncoder");
        props.put("partitioner.class", "storm.kafka.producer.CyouPartitioner");
        props.put("request.required.acks", "1");
        ProducerConfig config = new ProducerConfig(props);

        producer = new Producer&lt;String, String&gt;(config);
    }
</code></pre>

<p>将原来在Bolt构造函数里面初始化Producer，改为在prepare(&hellip;)中去初始化，最后再次执行就没有问题了。</p>

<p>总结：在bolt中做一些初始化的代码，要放到prepare(&hellip;)方法中，而不要放到构造函数中，因为prepare(&hellip;)方法是在Storm worker JVM中被调用，而构造函数是在Nimbus JVM中被调用而造成不会被serialized。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java-WebSocket]]></title>
    <link href="http://findhy.com/blog/2014/06/12/java-websocket/"/>
    <updated>2014-06-12T22:51:51+08:00</updated>
    <id>http://findhy.com/blog/2014/06/12/java-websocket</id>
    <content type="html"><![CDATA[<p>本文涉及到几个概念后面细说，Websocket协议、socket.io、Java-WebSocket，核心都是围绕Websocket，最后重点讲解在Java端实现Websocket的访问。</p>

<!--more-->


<h3>1.Websocket协议</h3>

<p>首先解释一下Websocket协议，<a href="http://zh.wikipedia.org/wiki/WebSocket">Wikipedia</a>的定义是：</p>

<blockquote><p>WebSocket是HTML5开始提供的一种浏览器与服务器间进行全双工通讯的网络技术</p></blockquote>

<p>什么是【全双工】？可以理解为双方经过对方确认可以互传数据了。客户端和服务器端建立<a href="http://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">TCP</a>连接的时候需要经过三次握手过程才能达到全双工的连接状态。在WebSocket API中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。</p>

<p>在Websocket协议之前，浏览器和服务器端最常用的是HTTP协议，而HTTP协议是半双工，服务器端无法实时向客户端发送消息，但是很多场景下我们又有这样的需求，以前的解决方案是浏览器端做轮询或者用Comet做长连接，两种方案都比较消耗资源。</p>

<p>Websocket协议的出现完全解决了这个问题，服务器端可实现主动推送数据到客户端。现在主流的浏览器Chrome、Firefox等都已经支持Websocket协议了。</p>

<p>而在服务器端，主流的web服务器和编程语言都对Websocket进行了支持，下面摘自Wikipedia：</p>

<ul>
<li>php &ndash; <a href="http://code.google.com/p/phpwebsocket/">http://code.google.com/p/phpwebsocket/</a></li>
<li>jetty &ndash; <a href="http://jetty.codehaus.org/jetty/">http://jetty.codehaus.org/jetty/</a> (版本7开始支持websocket)</li>
<li>netty &ndash; <a href="http://www.jboss.org/netty">http://www.jboss.org/netty</a></li>
<li>ruby &ndash; <a href="http://github.com/gimite/web-socket-ruby">http://github.com/gimite/web-socket-ruby</a></li>
<li>Kaazing &ndash; <a href="http://www.kaazing.org/confluence/display/KAAZING/Home">http://www.kaazing.org/confluence/display/KAAZING/Home</a></li>
<li>Tomcat &ndash; <a href="http://tomcat.apache.org/">http://tomcat.apache.org/</a> (7.0.26支持websocket)</li>
<li>WebLogic &ndash; <a href="http://www.oracle.com/us/products/middleware/cloud-app-foundation/-">http://www.oracle.com/us/products/middleware/cloud-app-foundation/-</a> weblogic/overview/index.html (12.1.2 开始支持)</li>
<li>node.js &ndash; <a href="https://github.com/Worlize/WebSocket-Node">https://github.com/Worlize/WebSocket-Node</a></li>
<li>node.js &ndash; <a href="http://socket.io">http://socket.io</a></li>
<li>nginx &ndash; <a href="http://nginx.com/">http://nginx.com/</a></li>
<li>mojolicious &ndash; <a href="http://mojolicio.us/">http://mojolicio.us/</a></li>
<li>python &ndash; <a href="https://github.com/abourget/gevent-socketio">https://github.com/abourget/gevent-socketio</a></li>
<li>Django &ndash; <a href="https://github.com/stephenmcd/django-socketio">https://github.com/stephenmcd/django-socketio</a></li>
<li>Java &ndash; <a href="http://java-websocket.org/">http://java-websocket.org/</a></li>
</ul>


<h3>2.socket.io</h3>

<p><a href="http://socket.io/">socket.io</a>一个是基于Node.js架构体系的，支持Websocket的协议用于时时通信的一个软件包。socket.io给跨浏览器构建实时应用提供了完整的封装，socket.io完全由javascript实现。Node.js实现Websocket访问的方式有很多种，socket.io是最常用的的。</p>

<p>和Node.js一样，socket.io是基于事件驱动模型，它使用Websocket协议，但同时对Adobe Flash sockets、JSONP polling、AJAX long polling也提供支持，它的源代码在这里<a href="https://github.com/Automattic/socket.io">socket.io-github</a>。</p>

<p>所以socket.io是一个对Websocket协议封装的javascript库，我们可以用它来完成客户端和服务器端的代码。</p>

<h3>3.Java-WebSocket</h3>

<p>我们有时会有这样的需求，就是在后台Java端去调用一个Websocket接口的服务，比如在Android端去请求一个公共Websocket服务，<a href="http://java-websocket.org/">Java-WebSocket</a>就是为了这样的需求而产生的，你可以完全用Java代码来实现Websocket的服务器端和客户端，而且它支持WSS，WSS是安全的Websocket连接，类似于HTTPS，下面我们来看一个客户端的例子，用Java实现用读取Wikipedia提供的Websocket接口：当前谁在Wikipedia上修改了文章。</p>

<p>POM文件添加依赖</p>

<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.java-websocket&lt;/groupId&gt;
    &lt;artifactId&gt;Java-WebSocket&lt;/artifactId&gt;
    &lt;version&gt;1.3.0&lt;/version&gt;
&lt;/dependency&gt; 
</code></pre>

<p>客户端Java类</p>

<pre><code>package storm.kafka.websocket;

import java.net.URI;
import java.net.URISyntaxException;

import org.java_websocket.client.WebSocketClient;
import org.java_websocket.drafts.Draft;
import org.java_websocket.drafts.Draft_10;
import org.java_websocket.framing.Framedata;
import org.java_websocket.handshake.ServerHandshake;

/**
 * This example demonstrates how to create a websocket connection to a server.
 * Only the most important callbacks are overloaded.
 */
public class TestWebsocket extends WebSocketClient {

    public TestWebsocket(URI serverUri, Draft draft) {
        super(serverUri, draft);
    }

    public TestWebsocket(URI serverURI) {
        super(serverURI);
    }

    @Override
    public void onOpen(ServerHandshake handshakedata) {
        System.out.println("opened connection");
        // if you plan to refuse connection based on ip or httpfields overload:
        // onWebsocketHandshakeReceivedAsClient
    }

    @Override
    public void onMessage(String message) {
        System.out.println("received: " + message);
    }

    public void onFragment(Framedata fragment) {
        System.out.println("received fragment: "
                + new String(fragment.getPayloadData().array()));
    }

    @Override
    public void onClose(int code, String reason, boolean remote) {
        // The codecodes are documented in class
        // org.java_websocket.framing.CloseFrame
        System.out.println("Connection closed by "
                + (remote ? "remote peer" : "us"));
    }

    @Override
    public void onError(Exception ex) {
        ex.printStackTrace();
        // if the error is fatal then onClose will be called additionally
    }

    public static void main(String[] args) throws URISyntaxException {
        TestWebsocket c = new TestWebsocket(new URI("ws://wikimon.hatnote.com:9000"),
                new Draft_10()); // more about drafts here:
                                    // http://github.com/TooTallNate/Java-WebSocket/wiki/Drafts
        c.connect();
    }

}
</code></pre>

<p>执行结果如下，可以接受到Wikipedia返回的当前修改的具体信息：</p>

<pre><code>opened connection
received: {"action": "edit", "change_size": 7, "flags": "M", "is_anon": false, "is_bot": false, "is_minor": true, "is_new": false, "is_unpatrolled": false, "ns": "Main", "page_title": "Siege of Amida (502\u2013503)", "parent_rev_id": "612641484", "rev_id": "575212259", "summary": "categorized for missing coordinate data", "url": "http://en.wikipedia.org/w/index.php?diff=612641484&amp;oldid=575212259", "user": "Kevinsam"}
received: {"action": "edit", "change_size": 38, "flags": null, "geo_ip": {"areacode": "", "city": "", "country_code": "US", "country_name": "United States", "ip": "71.167.104.60", "latitude": 38, "longitude": -97, "metro_code": "", "region_code": "", "region_name": "", "zipcode": ""}, "is_anon": true, "is_bot": false, "is_minor": false, "is_new": false, "is_unpatrolled": false, "ns": "Main", "page_title": "KMOV", "parent_rev_id": "612641485", "rev_id": "612641166", "summary": "/* History */", "url": "http://en.wikipedia.org/w/index.php?diff=612641485&amp;oldid=612641166", "user": "71.167.104.60"}
</code></pre>

<h3>4.总结</h3>

<p>Websocket协议是为了解决服务器推送数据到客户端而出现的由于HTTP协议的解决方案，基于Websocket协议又有很多实现，实现包括客户端和服务器端，客户端体现在主流的浏览器现在基本上都支持Websocket协议，服务器端体现在各个web服务器都对Websocket提供支持，各个编程语言也提供相应的实现包，让我们针对Websocket的开发更容易。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storm Spouts Lifecycle]]></title>
    <link href="http://findhy.com/blog/2014/06/10/storm-spouts-lifecycle/"/>
    <updated>2014-06-10T15:16:53+08:00</updated>
    <id>http://findhy.com/blog/2014/06/10/storm-spouts-lifecycle</id>
    <content type="html"><![CDATA[<p>Spouts是Storm中的Topology对应的消息生产者，消息将从Spouts发出，消息的单位是tuple，本文讲解Spouts核心方法以及Spouts方法的生命周期。相关接口方法看这里：<a href="http://storm.incubator.apache.org/apidocs/backtype/storm/spout/ISpout.html">ISpout</a>。Spouts在Storm中的位置可以参考下图：<br/>
<img src="http://findhy.com/images/storm-concepts.png"></p>

<!--more-->


<h3>1.初始化</h3>

<p>当我们自定义一个Spouts的时候，继承BaseRichSpout类，代码是这样的：</p>

<pre><code>public class TestWordSpout extends BaseRichSpout{

    public static Logger LOG = LoggerFactory.getLogger(TestWordSpout.class);
    SpoutOutputCollector _collector;

    @Override
    public void open(Map conf, TopologyContext context,SpoutOutputCollector collector) {
        _collector = collector;
    }

    @Override
    public void nextTuple() {

    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {

    }

}
</code></pre>

<p>BaseRichSpout是Storm提供的一个抽象类，代码如下：</p>

<pre><code>/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package backtype.storm.topology.base;

import backtype.storm.topology.IRichSpout;

/**
 *
 * @author nathan
 */
public abstract class BaseRichSpout extends BaseComponent implements IRichSpout {
    @Override
    public void close() {
    }

    @Override
    public void activate() {
    }

    @Override
    public void deactivate() {
    }

    @Override
    public void ack(Object msgId) {
    }

    @Override
    public void fail(Object msgId) {
    }
}
</code></pre>

<p>可以看到BaseRichSpout没有做任何事情就是实现了接口的方法，没有任何具体实现，这样子类不用显式实现方法了，它继承了BaseComponent，实现了接口IRichSpout，而IRichSpout接口是继承自ISpout, IComponent这两个接口，BaseComponent类如下：</p>

<pre><code>package backtype.storm.topology.base;

import backtype.storm.topology.IComponent;
import java.util.Map;

public abstract class BaseComponent implements IComponent {
    @Override
    public Map&lt;String, Object&gt; getComponentConfiguration() {
        return null;
    }
}
</code></pre>

<p>可以看到BaseComponent只是实现了接口的方法getComponentConfiguration()返回null。   <br/>
下面来看下ISpout, IComponent这两个接口</p>

<pre><code>package backtype.storm.topology;

import java.io.Serializable;
import java.util.Map;

public interface IComponent extends Serializable {

    void declareOutputFields(OutputFieldsDeclarer declarer);

    Map&lt;String, Object&gt; getComponentConfiguration();

}

package backtype.storm.spout;

import backtype.storm.task.TopologyContext;
import java.util.Map;
import java.io.Serializable;

public interface ISpout extends Serializable {

    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);

    void close();

    void activate();

    void deactivate();

    void nextTuple();

    void ack(Object msgId);

    void fail(Object msgId);
}
</code></pre>

<p>上面把javadoc都去掉，如果要看的话直接看源码，或者到这里看：<a href="http://storm.incubator.apache.org/apidocs  ">http://storm.incubator.apache.org/apidocs  </a>
到这里基本可以看到核心的接口方法主要在IComponent和ISpou这两个接口中定义，下面详细讲解。</p>

<h3>2.IComponent接口方法详解</h3>

<p>IComponent接口是topology中所有组件的顶层接口，包括Spouts、Bolts，它定义了两个核心的公共方法：</p>

<pre><code>    /**
     * 该方法是用来定义topology中的spout或者bolt的ID，而且该ID在同是spouts或者bolts内部不能重复，但是spouts和bolts之间的ID可以重复
     * 如果没有显示指定该值，则默认使用Utils.DEFAULT_STREAM_ID这个值
     * 这里可以参考Storm源码TopologyBuilder类里面的validateUnusedId这个方法
     * 
     * 该方法在客户端调用createTopology()方法时被执行，同样参见TopologyBuilder类
     * 
     * 源码：https://github.com/nathanmarz/storm/blob/moved-to-apache/storm-core/src/jvm/backtype/storm/topology/TopologyBuilder.java#L226
     */
    void declareOutputFields(OutputFieldsDeclarer declarer);

    /**
     * 该方法可以用来配置组件
     * 
     * Declare configuration specific to this component. Only a subset of the "topology.*" configs can
     * be overridden. The component configuration can be further overridden when constructing the 
     * topology using {@link TopologyBuilder}
     *
     */
    Map&lt;String, Object&gt; getComponentConfiguration();
</code></pre>

<h3>3.ISpout接口方法详解</h3>

<pre><code>    /**
     * 该方法在task任务组件在worker里初始化的时候被调用，它提供了spout的执行环境
     * Called when a task for this component is initialized within a worker on the cluster.
     * It provides the spout with the environment in which the spout executes.
     *
     * &lt;p&gt;This includes the:&lt;/p&gt;
     *
     * @param conf The Storm configuration for this spout. This is the configuration 
     * provided to the topology merged in with cluster configuration on this machine.
     * @param context This object can be used to get information about this task's place 
     * within the topology, including the task id and component id of this task, input 
     * and output information, etc.
     * 
     * @param collector The collector is used to emit tuples from this spout. 
     * Tuples can be emitted at any time, including the open and close methods. 
     * The collector is thread-safe and should be saved as an instance variable of this spout object.
     */
    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);

    /**
     * Spout停掉的时候会调用此方法
     * 
     * Called when an ISpout is going to be shutdown. There is no guarentee that close
     * will be called, because the supervisor kill -9's worker processes on the cluster.
     *
     * &lt;p&gt;The one context where close is guaranteed to be called is a topology is
     * killed when running Storm in local mode.&lt;/p&gt;
     */
    void close();

    /**
     * spout由deactivated模式转为activated模式时被调用
     * 
     * Called when a spout has been activated out of a deactivated mode.
     * nextTuple will be called on this spout soon. A spout can become activated
     * after having been deactivated when the topology is manipulated using the 
     * `storm` client. 
     */
    void activate();

    /**
     * spout被deactivated的时候调用，并且当spout被deactivated时，nextTuple就不会被调用了
     * 
     * Called when a spout has been deactivated. nextTuple will not be called while
     * a spout is deactivated. The spout may or may not be reactivated in the future.
     */
    void deactivate();

    /**
     * spout发射Tuple时被调用，该方法必须是非阻塞的（non-blocking），这样如果Spout没有tuples可以发射了，
     * 这个方法也会返回，nextTuple, ack, and fail这几个方法在同一个spout task同一个线程里面是会被循环调用的，
     * 当没有tuples可以发射了，应该让线程sleep一段时间
     * 这样就不会占用太多的CPU资源了
     * 
     * When this method is called, Storm is requesting that the Spout emit tuples to the 
     * output collector. This method should be non-blocking, so if the Spout has no tuples
     * to emit, this method should return. nextTuple, ack, and fail are all called in a tight
     * loop in a single thread in the spout task. When there are no tuples to emit, it is courteous
     * to have nextTuple sleep for a short amount of time (like a single millisecond)
     * so as not to waste too much CPU.
     */
    void nextTuple();

    /**
     * Storm可以保证spout发射出去的tuples必须被处理了，msgId就是就是发射的消息的ID
     * 当tuples被处理完了之后，该方法会被调用，并且将它从队列中去掉防止被反复处理
     * 
     * Storm has determined that the tuple emitted by this spout with the msgId identifier
     * has been fully processed. Typically, an implementation of this method will take that
     * message off the queue and prevent it from being replayed.
     */
    void ack(Object msgId);

    /**
     * 如果msgId对应的tuples处理失败，该方法会被调用，通常的实现会将tuples重新放回队列，让它多一段时间可以被处理
     * 上面两个方法ack和fail是Storm保证数据一定被处理和避免重复处理的机制，
     * 参数msgId就是每次发射tuples的时候spout提供的一个
     * message-id，后面可以通过这个message-id来追踪这个tuple
     * 
     * The tuple emitted by this spout with the msgId identifier has failed to be
     * fully processed. Typically, an implementation of this method will put that
     * message back on the queue to be replayed at a later time.
     */
    void fail(Object msgId);
</code></pre>

<h3>4.总结</h3>

<ul>
<li>客户端提交Topology的时候，首先调用declareOutputFields(&hellip;)方法，指定spout和bolt的ID，如果没有实现该方法则默认为Utils.DEFAULT_STREAM_ID</li>
<li>然后Storm会在worker进程内初始化task的运行环境，再调用open(&hellip;)方法，传回SpoutOutputCollector对象，后面我们后可以SpoutOutputCollector来发射tuples</li>
<li>然后Storm就会反复调用spout的nextTuple方法获取下一个tuple，如果任务处理成功了就调用ack方法，如果任务处理失败就调用fail方法</li>
<li>并且Spout发射tuple会提供一个message-id，后面我们通过这个message-id来追踪这个tuple，ack和fail接受的参数就是该message-id</li>
<li>一个tuple可能会产生多个tuple，最终形成一个tuple树，Storm会跟踪整个tuple树，如果其中一个叶子tuple失败，那么整个tuple树会重新被处理</li>
<li>值得注意的一点是，storm调用ack或者fail的task始终是产生这个tuple的那个task。所以如果一个spout被分成很多个task来执行， 消息执行的成功失败与否始终会通知最开始发出tuple的那个task</li>
<li>每个你处理的tuple， 必须被ack或者fail。因为storm追踪每个tuple要占用内存。所以如果你不ack/fail每一个tuple， 那么最终你会看到OutOfMemory错误。</li>
</ul>


<p>本文参考：<br/>
<a href="http://xumingming.sinaapp.com/127/twitter-storm%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/">Storm如何保证消息不丢失</a><br/>
<a href="http://stackoverflow.com/questions/21689059/with-storm-spouts-when-is-declareoutputfields-called">storm-spouts</a><br/>
<a href="http://storm.incubator.apache.org/apidocs">storm-javadocs</a><br/>
<a href="http://xumingming.sinaapp.com/117/twitter-storm%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/">storm的一些关键概念</a><br/>
<a href="http://xumingming.sinaapp.com/138/twitter-storm%E5%85%A5%E9%97%A8/">storm入门</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kafka vs MQ vs JMS]]></title>
    <link href="http://findhy.com/blog/2014/06/10/kafka-vs-mq-vs-jms/"/>
    <updated>2014-06-10T10:43:08+08:00</updated>
    <id>http://findhy.com/blog/2014/06/10/kafka-vs-mq-vs-jms</id>
    <content type="html"><![CDATA[<p>Kafka的介绍参加这篇文章：<a href="http://findhy.com/blog/2014/05/18/kafka/">Kafka Introduction</a>，本文将Kafka、MQ、JMS这几个概念重新梳理一下，当然它们之间是有包含的关系，还有已经有了那么多的MQ产品，为什么LinkedIn还要开发Kafka呢？</p>

<!--more-->


<h3>1.MQ</h3>

<p>MQ的全称是Message Queue，中文名叫消息队列，是一种进程间通信或同一进程的不同线程间的通信方式，进程将消息存入链表数据结构中，然后其它拥有权限的进程去读取消息，这个过程是异步的，就是说消息接受者需要去轮询消息队列。详细可以参考Wikipedia的介绍：<a href="http://zh.wikipedia.org/wiki/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97">Message Queue</a>。</p>

<p>MQ是一种标准或者是一种通信方式，它是一个逻辑概念或者一个定义，不是一个具体的产品，但是有很多产品按照它定义的标准来实现，包括：JBoss Messaging、JORAM、<strong>Apache ActiveMQ</strong>、Sun Open Message Queue、Apache Qpid、HTTPSQS、Sparrow、Starling、<strong>Kestrel</strong>、<strong>RabbitMQ</strong>、Beanstalkd、<strong>Amazon SQS</strong>、<strong>Kafka</strong>、<strong>ZeroMQ</strong>、EagleMQ、IronMQ、FQueue、Spring AMQP、HornetQ、MQSSave、FFMQ、JMS4Spread、mom4j、OpenJMS、UberMQ等。这些都是Message Queue，关于这些产品的介绍可以去Google，或者参考下面两个链接：
<a href="http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or  ">http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or  </a>
<a href="http://www.open-open.com/53.htm%E3%80%82">http://www.open-open.com/53.htm%E3%80%82</a></p>

<h3>2.JMS</h3>

<p>JMS全称是Java Message Service，可见它是Java平台的Message Queue，而且它不是一个逻辑概念而是有一套面向消息中间件（MOM）的API，在javax.jms包内，但是要使用JMS，还要有一个JMS提供者来管理会话和队列，这个提供者就是JMS消息中间件（MOM），有哪些呢，开源的包括：Apache ActiveMQ、JBoss 社区所研发的 HornetQ、Joram、Coridan的MantaRay、The OpenJMS Group的OpenJMS等，商业的包括：BEA的BEA WebLogic Server JMS、TIBCO软件公司的EMS、GigaSpaces Technologies的GigaSpaces、IBM的WebSphere MQ等。JMS其它更多的可以参考Wikipedia的介绍：<a href="http://zh.wikipedia.org/wiki/JMS">JMS</a>。</p>

<h3>3.Kafka</h3>

<p>Kafka的介绍以及特性还有它在hadoop生态系统中的位置，可以参考这篇文章：<a href="http://findhy.com/blog/2014/05/18/kafka/">Kafka Introduction</a>，已经有了那么多的MQ产品，LinkedIn为什么还要再开发Kafka呢？目前业界比较成熟的MQ产品RabbitMQ、ZeroMQ、ActiveMQ，Kafka和它们相比有哪些优势？</p>

<p>关于RabbitMQ、ZeroMQ、ActiveMQ这几个的对比，可以参考这里：<br/>
<a href="http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or  ">http://stackoverflow.com/questions/731233/activemq-or-rabbitmq-or-zeromq-or  </a>
<a href="http://itindex.net/detail/43897-%E6%B6%88%E6%81%AF-%E4%B8%AD%E9%97%B4%E4%BB%B6-%E6%8A%80%E6%9C%AF">http://itindex.net/detail/43897-%E6%B6%88%E6%81%AF-%E4%B8%AD%E9%97%B4%E4%BB%B6-%E6%8A%80%E6%9C%AF</a></p>

<p>Kafka与RabbitMQ比较可以参考这里：<br/>
<a href="http://www.quora.com/RabbitMQ/RabbitMQ-vs-Kafka-which-one-for-durable-messaging-with-good-query-features">http://www.quora.com/RabbitMQ/RabbitMQ-vs-Kafka-which-one-for-durable-messaging-with-good-query-features</a></p>

<p>Kafka拥有更高的吞吐量和更好的分布式支持。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Computational Advertising]]></title>
    <link href="http://findhy.com/blog/2014/06/07/computational-advertising/"/>
    <updated>2014-06-07T12:50:40+08:00</updated>
    <id>http://findhy.com/blog/2014/06/07/computational-advertising</id>
    <content type="html"><![CDATA[<p>最近在学习计算广告学，一个互联网广告行业催生出来的新兴学科，斯坦福大学已经推出了计算广告学的课程，本文下面有公开课的链接。</p>

<!--more-->


<h3>一、综述</h3>

<h4>1.由来</h4>

<p>互联网行业的发展，广告由线下搬到了线上，而线上广告与用户的交互与线下有很大的不同，怎么样让互联网广告更加有效，就是计算广告学这门学科研究的内容。</p>

<h4>2.参与方</h4>

<p>在互联网广告整个生命周期中，一般会有四个参与方，这里引用微软一篇文章里面的图：<br/>
<img src="http://findhy.com/images/ad1.png"></p>

<ul>
<li>需求方(Demand): 图中的广告主，可以是广告主(advertiser),也可以是代表广告主利益的代理商(agency)</li>
<li>供给方(Supply): 图中的网页出版商，一般指互联网媒体，有流量的且可以提供广告位的媒体方。</li>
<li>受众(Audience)：图中的网络用户，就是广告面向的用户</li>
<li>广告平台：这个在下一节详细讲</li>
</ul>


<h4>3.广告分类</h4>

<p>引用刘鹏计算广告学：</p>

<blockquote><p>品牌广告(Brand Awareness): 希望借助媒体的力量来快速接触大量用户,以达到宣传品牌形象,提升中长期购买率与利润空间的目的。<br/>
效果广告(Direct Response): 希望能利用广告手段马上带来大量的购买行为。</p></blockquote>

<h3>二、广告平台</h3>

<p>在互联网广告这个生态系统中，需求方、供给方、受众是比较容易理解，需求方和线下广告的没有区别，就是广告主或者代理商，它是广告的买方也是广告效果的最终受益者，供给方就是有流量且可以提供广告位的媒体，受众就是最终用户。</p>

<p>广告平台主要有三类，需求方平台(Demand Side Platform, DSP)、供应方平台（Sell-Side Platform，SSP）和广告交易平台(Ad Exchange)。</p>

<h4>1.广告交易平台(Ad Exchange)</h4>

<p>引用刘鹏计算广告学：</p>

<blockquote><p>提供广告主自行选择流量和在每次展示上独立定价的功能。这样的功能，必然要求竞价这一过程在每次展示时实时进行，也就是实时竞价(Real Time Bidding, RTB)。RTB的产生，使得广告市场向着透明的比价平台的方向发展，这样的平台就是广告交易平台(Ad Exchange)，其主要特征即是用RTB的方式实时得到广告候选，并按照其出价简单完成投放决策。</p></blockquote>

<p>广告交易平台通常应该是一个中立的平台，它汇集了大量媒体（供给方）的流量，让需求方以实时竞价的方式来购买广告位。</p>

<h4>2.需求方平台（DSP）</h4>

<p>引用刘鹏计算广告学：</p>

<blockquote><p>DSP的系统广告投放的决策流程为：DSP服务器通过RTBS接口拿到广告请求，然后经过与广告网络类似的决策步骤，包括检索和eCPM排序，找到价值最高的广告，并将报价返回给Ad Exchange。与广告网络相比，DSP的广告决策过程有一些难点：一是在eCPM估计时，除了估计CTR，还要估计点击价值，并且由于出价的要求，这一估计要尽可能准确；二是由于DSP是完全面向广告主的产品，广告主量的需求也需要满足，因此还要考虑在线分配的策略。DSP与其它广告产品的相比，多了定制化用户划分功能，即图中的Customized Audience Segmentation部分。这部分通常的方式是在广告主网站上布DSP域名的代码，收集到用户行为并进行离线加工分析，再将加工出的标签用于广告投放。</p></blockquote>

<p>DSP代表需求方的利益，它的核心是广告与用户的准确匹配以及预估点击价值。</p>

<h4>3.供应方平台（SSP）</h4>

<p>SSP代表供给方（媒体）的利益，它有流量、广告位和广告库，通过人工和算法调节达到利益最大化，举个例子，我有一个媒体A，有广告位1、2，接入了广告主甲、乙、丙，按CPC结算，甲和乙的受众是男性，丙的受众是女性，那如果我发现流量用户的属性是男性，那么广告位肯定要展现甲和乙的广告，而不展现丙，这是一个最简单的受众定向来达到用户点击率最大化。</p>

<h4>4.DSP与SSP关系</h4>

<p><img src="http://findhy.com/images/ad2.png"></p>

<h3>三、广告系统技术架构</h3>

<p>TODO</p>

<h3>四、本文参考</h3>

<p>刘鹏的计算广告学<br/>
<a href="http://dirlt.com/computational-advertising.html  ">http://dirlt.com/computational-advertising.html  </a>
<a href="http://study.163.com/course/courseMain.htm?courseId=321007#/courseMain">http://study.163.com/course/courseMain.htm?courseId=321007#/courseMain</a></p>

<p>方兴未艾的计算广告学<br/>
<a href="http://www.vision-computing.org/userfiles/file/2013-4//20134221848115974.pdf">http://www.vision-computing.org/userfiles/file/2013-4//20134221848115974.pdf</a></p>

<p>斯坦福大学的计算广告学公开课<br/>
<a href="http://www.stanford.edu/class/msande239/">http://www.stanford.edu/class/msande239/</a></p>

<p>雅虎的相关研究论文<br/>
<a href="http://research.yahoo.com/Computational_Advertising">http://research.yahoo.com/Computational_Advertising</a></p>

<p>知乎讨论<br/>
<a href="http://www.zhihu.com/question/20363959">http://www.zhihu.com/question/20363959</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open Datasource]]></title>
    <link href="http://findhy.com/blog/2014/06/05/big-data-open-source/"/>
    <updated>2014-06-05T20:43:54+08:00</updated>
    <id>http://findhy.com/blog/2014/06/05/big-data-open-source</id>
    <content type="html"><![CDATA[<p>大数据时代没有数据是玩不转的，真正拥有大数据的公司少之又少，更何况是个人开发者呢。数据有很多，最接近用户诉求、最能够精准定位用户需求的数据是最具有商业价值的，像搜索、电商、社交，而拥有这些数据的公司：Google、Facebook、百度、阿里巴巴、亚马逊等，它们首先会通过广告、增值服务等形式来将数据变现，肯定不会将数据开放出来，而且未来数据会越来越成为一个公司的核心竞争力。</p>

<p>对于大数据研究人员或者创业者，我们有哪些数据可以使用呢？我简单整理了一下。</p>

<!--more-->


<h3>1.数据分类</h3>

<p>我将数据分为两类：</p>

<ul>
<li>静态大数据（Batch Data）：通常是一个备份数据集，容量往往很大</li>
<li>动态流数据（Streaming Data）：这是实时变动的数据，数据不断的更新和涌入</li>
</ul>


<!--more-->


<h3>2.数据来源</h3>

<h4>2.1 政府/非盈利机构（部分）</h4>

<p>国内：<br/>
<a href="http://www.stats.gov.cn/  ">http://www.stats.gov.cn/  </a>
<a href="http://www.bosidata.com/  ">http://www.bosidata.com/  </a>
<a href="http://www.cnnic.cn/  ">http://www.cnnic.cn/  </a>
<a href="http://www.eguan.cn/">http://www.eguan.cn/</a></p>

<p>国外：<br/>
如果你在AWS上，这上面的可以看看，直接从S3 get下来。<br/>
<a href="http://aws.amazon.com/datasets">http://aws.amazon.com/datasets</a></p>

<p>freebase包含了很多开源项目的数据<br/>
<a href="https://developers.google.com/freebase/data">https://developers.google.com/freebase/data</a></p>

<p>这是一个很有商业价值的数据，包含互联网上所有的网页信息，相当于Google的数据
<a href="http://commoncrawl.org/data/">http://commoncrawl.org/data/</a></p>

<p>想做一些项目，Wikipedia的数据足够了，它既有Batch Data，也有Streaming Data。
<a href="http://en.wikipedia.org/wiki/Wikipedia:Database_download">http://en.wikipedia.org/wiki/Wikipedia:Database_download</a></p>

<p>这是一个开放数据源的集合，里面有很多公开的金融的社会统计数据，可以下载也可是可视化显示，非常适合研究和教学<br/>
<a href="http://www.quandl.com/">http://www.quandl.com/</a></p>

<h4>2.2 商业公司</h4>

<p>商业公司开放的数据通常都是有限制条件的，往往以一种合作的方式，而且基本上都是Streaming Data数据接口，案例有很多，像Twitter、腾讯、新浪微博，都有开放数据接口给个人开发者。<br/>
Twitter：<a href="https://dev.twitter.com/docs/api/1.1/post/statuses/filter">https://dev.twitter.com/docs/api/1.1/post/statuses/filter</a></p>

<p>腾讯：<a href="http://open.qq.com/">http://open.qq.com/</a></p>

<p>新浪微博：<a href="http://open.weibo.com/">http://open.weibo.com/</a></p>

<p>商业公司希望通过开放平台来构建一个以它为中心的生态系统，当然数据开放只是其中一部分。</p>

<h4>2.3 其它数据资源社区</h4>

<p>数据堂（主要是国内的政府机构数据）：<a href="http://www.datatang.com/">http://www.datatang.com/</a></p>

<p>本文整理参考：  <br/>
<a href="http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public">http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public</a></p>

<p><a href="http://www.datapanda.net/123/">http://www.datapanda.net/123/</a></p>

<p><a href="http://www.zhihu.com/question/19969760">http://www.zhihu.com/question/19969760</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[S3cmd Configure]]></title>
    <link href="http://findhy.com/blog/2014/06/05/s3cmd-config/"/>
    <updated>2014-06-05T18:52:03+08:00</updated>
    <id>http://findhy.com/blog/2014/06/05/s3cmd-config</id>
    <content type="html"><![CDATA[<p>s3cmd是AWS S3的命令行工具，可以用来下载、上传、同步文件，还可以配置权限。</p>

<!--more-->


<h3>一、配置</h3>

<h4>1.安装python-pip</h4>

<pre><code>yum install python-pip
</code></pre>

<p>如果提示No package python-pip available，先安装<a href="http://dl.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm">epel-release-6-8.noarch.rpm</a></p>

<pre><code>rpm -ivh epel-release-6-8.noarch.rpm
</code></pre>

<h4>2.安装s3cmd</h4>

<pre><code>pip install s3cmd
</code></pre>

<h4>3.配置s3cmd</h4>

<pre><code>s3cmd --configure
</code></pre>

<p>分别输入Access Key和Secret Key</p>

<pre><code>Access Key:
Secret Key:
</code></pre>

<p>回车，如果提示：</p>

<pre><code>Encryption password is used to protect your files from reading
by unauthorized persons while in transfer to S3
Encryption password:
</code></pre>

<p>输入当前登录的操作系统用户</p>

<h4>4.HTTPS协议选择no</h4>

<pre><code>Use HTTPS protocol [No]: no
</code></pre>

<h4>5.代理不填直接回车</h4>

<pre><code>HTTP Proxy server name: 
</code></pre>

<h4>6.最后就是测试保存</h4>

<pre><code>Test access with supplied credentials? [Y/n] y
Save settings? [y/N] y
</code></pre>

<h4>7.测试</h4>

<pre><code>s3cmd ls
</code></pre>

<h4>8.下载整个目录</h4>

<pre><code>s3cmd get --recursive dir_name
</code></pre>

<h3>二、使用</h3>

<h4>1.查看所有的Buckets</h4>

<pre><code>s3cmd ls
</code></pre>

<h4>2.创建Buckets</h4>

<pre><code>s3cmd mb s3://my-bucket-name
</code></pre>

<h4>3.删除空Buckets</h4>

<pre><code>s3cmd rb s3://my-bucket-name
</code></pre>

<h4>4.上传</h4>

<pre><code>上传单个文件：s3cmd put file.txt s3://my-bucket-name/file.txt
批量上传：s3cmd put ./* s3://my-bucket-name/
上传整个目录：s3cmd put -r dir1 s3://my-bucket-name/
上传目录下所有文件：s3cmd put -r dir1/ s3://my-bucket-name/
</code></pre>

<h4>5.下载</h4>

<pre><code>下载单个文件：s3cmd get s3://my-bucket-name/file.txt file.txt
下载整个目录下的文件：s3cmd get -r  s3://my-bucket-name/bucket_dir ./
</code></pre>

<h4>6.删除文件</h4>

<pre><code>s3cmd del s3://my-bucket-name/file.txt
</code></pre>

<h4>7.查看空间大小</h4>

<pre><code>s3cmd du -H s3://my-bucket-name
</code></pre>

<h4>8.同步</h4>

<pre><code>同步当前目录下所有文件：s3cmd sync  ./  s3://my-bucket-name/
只列出不同步：s3cmd sync  --dry-run ./  s3://my-bucket-name/
同步且删除本地不存在的文件：s3cmd sync  --delete-removed ./  s3://my-bucket-name/
不检验跳过本地已经存在的文件：s3cmd sync  --skip-existing ./  s3://my-bucket-name/
排除包含文件规则：s3cmd sync --dry-run --exclude '*.txt' --include 'dir2/*' ./ 
更多参考这里：http://s3tools.org/s3cmd-sync
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Swift Introduction]]></title>
    <link href="http://findhy.com/blog/2014/06/04/swift/"/>
    <updated>2014-06-04T09:51:16+08:00</updated>
    <id>http://findhy.com/blog/2014/06/04/swift</id>
    <content type="html"><![CDATA[<p>Swift是Apple下一代开发语言，并且为了保证兼容性，Swift代码可以和Objective-C代码共存（官方解释是：New Swift code co-exists along side your existing Objective-C files in the same project）。下面介绍一下它的特性：</p>

<!--more-->


<ul>
<li>并行（parallel）：it runs multiple programs concurrently as soon as their inputs are available, reducing the need for complex parallel programming</li>
<li>简单（easy）：Short, simple scripts can do large-scale work. The same script runs on multicore computers, clusters, grids, clouds, and supercomputers</li>
<li>快（fast）：it can run a million programs, thousands at a time, launching hundreds per second</li>
<li>灵活（flexible）：its being used in many fields of science, engineering, and business. Read the case studies</li>
</ul>


<p>官网：<a href="http://swift-lang.org/">http://swift-lang.org/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Protocol Buffers vs Avro vs Thrift]]></title>
    <link href="http://findhy.com/blog/2014/05/18/protocol-buffers/"/>
    <updated>2014-05-18T15:53:37+08:00</updated>
    <id>http://findhy.com/blog/2014/05/18/protocol-buffers</id>
    <content type="html"><![CDATA[<p>分布式架构一个重要的思路是解耦，将系统拆解为很多个相互独立的组件，每个组件通过接口对外提供服务，这种面向服务（SOA）架构设计可伸缩性更强、维护成本也更低。但服务的管理、分布式锁、高效的组件调用等相关技术复杂性也更高。本文介绍几个常用的高效的RPC框架。</p>

<!--more-->


<h3>1.RPC模型</h3>

<p>一个简单的RPC调用模型如下图所示：<br/>
<img src="http://findhy.com/images/rpc_1.png"></p>

<p>当我们在选型RPC框架的时候需要关注的几个核心问题是：</p>

<ul>
<li>传输的协议和数据（JSON、XML等）是什么？</li>
<li>如何高效的数据存储和传输？</li>
<li>服务器端处理请求的方式？</li>
</ul>


<h3>2.不建议的方案</h3>

<ul>
<li>SOAP：基于XML，传输的数据太多</li>
<li>CORBA：多度设计而且重量级，<a href="http://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture">http://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture</a></li>
<li>DCOM, COM+ :主要用于windows客户端程序</li>
<li>HTTP/JSON/XML/Plain Text：基于HTTP协议的，这种在简单的场景下是可以用的，像hessian，但缺点是缺乏更复杂的协议描述，只能传输简单的对象，而且JSON/XML都太重了</li>
</ul>


<h3>3.建议方案</h3>

<ul>
<li>Protocol Buffers</li>
<li>Apache Thrift</li>
<li>Apache Avro</li>
<li>Message Pack</li>
<li>kryo</li>
<li>BSON</li>
</ul>


<p>上面这些序列化框架共同的特点的是：有接口描述（IDL）、性能较高、版本控制和基于二进制的数据传输。下面重点介绍前三个。</p>

<h3>4.Protocol Buffers</h3>

<ul>
<li>来源Google，于2001年开始设计，2008年开源</li>
<li>非常稳定，大量运用在Google的生产环境中</li>
<li>目前支持四种语言：C++, Java, Python, and JavaScript</li>
<li><a href="https://code.google.com/p/protobuf/">https://code.google.com/p/protobuf/</a></li>
</ul>


<h3>5.Apache Thrift</h3>

<ul>
<li>由Google-X实验室的工程师于2007年设计，后来主要用于Facebook内部项目，现在为apache的开源项目</li>
<li>旨在成为下一代的PB（更加全面的功能和支持更多的语言）</li>
<li>支持更多语言，包括：C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#,
Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi等</li>
<li>IDL描述语言要比PB更简洁</li>
<li>提供一个RPC调用栈</li>
<li><a href="http://thrift.apache.org/">http://thrift.apache.org/</a></li>
</ul>


<h3>6.Apache Avro</h3>

<ul>
<li>Avro是Hadoop的作者Doug Cutting写的另外一个RPC框架</li>
<li>支持序列化为JSON或者二进制</li>
<li>支持从protobufs和thrift读写数据</li>
<li>支持语言：Java, C, C++, C#, Python, Ruby</li>
<li><a href="http://avro.apache.org/">http://avro.apache.org/</a></li>
</ul>


<h3>7.传输数据大小比较</h3>

<p><img src="http://findhy.com/images/rpc_2.png"></p>

<p>Thrift-TBinaryProtocol &ndash; 没有经过压缩的二进制协议，比文本协议要快，但是很难调试<br/>
Thrift-TCompactProtocol &ndash; 经过压缩处理的，更加高效</p>

<h3>8.哪些项目在使用Thrift？</h3>

<ul>
<li>Facebook</li>
<li>Cassandra project</li>
<li>Hadoop supports access to its HDFS API through Thrift bindings</li>
<li>HBase leverages Thrift for a cross-language API</li>
<li>Hypertable leverages Thrift for a cross-language API since v0.9.1.0a</li>
<li>LastFM</li>
<li>DoAT</li>
<li>ThriftDB</li>
<li>Scribe</li>
<li>Evernote uses Thrift for its public API.</li>
<li>Junkdepot</li>
</ul>


<h3>9.哪些项目在使用Protocol Buffers？</h3>

<ul>
<li>Google</li>
<li>ActiveMQ uses the protobuf for Message store</li>
<li>Netty (protobuf-rpc)</li>
</ul>


<h3>10.不同框架测试结果比较</h3>

<p><a href="https://code.google.com/p/thrift-protobuf-compare/wiki/BenchmarkingV2">https://code.google.com/p/thrift-protobuf-compare/wiki/BenchmarkingV2</a></p>

<h3>11.总结</h3>

<ul>
<li>其实大部分场景下，基于HTTP的Hessian或者阿里巴巴的Dubbo完全可以满足需求</li>
<li>如果追求更高的性能，像高并发的游戏服务器端，可以选择Protocol Buffers、Avro或Thrift</li>
<li>Protocol Buffers和Thrift的稳定性要更好，大量运用于Google和Facebook的生产环境中</li>
<li>Thrift相比Protocol Buffers支持更多的语言，框架逻辑更加清晰，易于定制扩展，性能与Protocol Buffers不相上下，目前来说应该是最佳的选择</li>
<li>Avro的优势在于Schema动态加载功能，而且Avro更适合于数据交换及存储的通用工具和平台</li>
<li>Avro的性能不输Protocol Buffers和Thrift，但缺点是发展时间较短，没有经过太多项目的验证</li>
</ul>


<h3>12.参考</h3>

<p><a href="http://www.slideshare.net/ChicagoHUG/avro-chug-20120416">http://www.slideshare.net/ChicagoHUG/avro-chug-20120416</a>
<a href="http://www.slideshare.net/IgorAnishchenko/pb-vs-thrift-vs-avro">http://www.slideshare.net/IgorAnishchenko/pb-vs-thrift-vs-avro</a>
<a href="http://ganges.usc.edu/pgroupW/images/a/a9/Serializarion_Framework.pdf  ">http://ganges.usc.edu/pgroupW/images/a/a9/Serializarion_Framework.pdf  </a>
<a href="https://www.igvita.com/2011/08/01/protocol-buffers-avro-thrift-messagepack/http://www-old.itm.uni-luebeck.de/teaching/ws1112/vs/Uebung/GrossUebungNetty/VS-WS1112-xx-Zero-Copy_Event-Driven_Servers_with_Netty.pdf?lang=de">https://www.igvita.com/2011/08/01/protocol-buffers-avro-thrift-messagepack/http://www-old.itm.uni-luebeck.de/teaching/ws1112/vs/Uebung/GrossUebungNetty/VS-WS1112-xx-Zero-Copy_Event-Driven_Servers_with_Netty.pdf?lang=de</a>  <br/>
<a href="http://www.alidata.org/archives/1307">http://www.alidata.org/archives/1307</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kafka Introduction]]></title>
    <link href="http://findhy.com/blog/2014/05/18/kafka/"/>
    <updated>2014-05-18T10:25:44+08:00</updated>
    <id>http://findhy.com/blog/2014/05/18/kafka</id>
    <content type="html"><![CDATA[<p>Kafka是Linkedin于2010开源的消息系统，现在已经放到Apache的项目中了，主页是：<a href="http://kafka.apache.org/%E3%80%82">http://kafka.apache.org/%E3%80%82</a>
Kafka是一个高吞吐量分布式的消息系统（publish-subscribe），它有如下这些特点：</p>

<!--more-->


<ul>
<li>高性能：单个Kafka broker节点就可以处理来自数千个客户端数百MB的消息读取和写入。</li>
<li>可扩展：集群设计可以保证弹性扩展而不停机</li>
<li>持久化：消息被持久化到磁盘上，并且在集群内会有复制备份，所以不会有数据丢失。并且每一个broker可以处理TB级的消息而不影响性能</li>
<li>分布式：分布式集群设计保证了系统的健壮性和容错性</li>
</ul>


<h4>Kafka的部署结构图</h4>

<p><img src="http://findhy.com/images/kafka.png"></p>

<h4>为什么要用Kafka</h4>

<ul>
<li>统一消息入口<br/>
Storm流数据平台需要处理的数据多种多样，如果直接用Storm来接入，会需要写很多的接口，这样必然不是最佳的解决方案，加了一层Kafka之后，Storm只需要处理来自Kafka的数据，由Kafka对接数据源。</li>
<li>消息持久化<br/>
直接用Storm或者其它MQ会发生数据丢失的可能，而Kafka是把数据持久化到磁盘上面而且会有复制备份，所以不会发生数据丢失。</li>
<li>支持分布式<br/>
支持分布式保证了架构的健壮性、弹性扩展和容错。</li>
</ul>


<p>Kafka在数据平台中的位置如图：<br/>
<img src="http://findhy.com/images/kafka_hadoop.png"></p>

<p>Kafka作为消息中间件，为Storm提供数据来源。<br/>
Zookeeper为Kafka、Storm、HBase提供分布式协调服务，所以单独部署，不用HBase自带的Zookeeper。<br/>
HBase作为Storm的持久化层，也作为Titan的数据存储层。</p>
]]></content>
  </entry>
  
</feed>

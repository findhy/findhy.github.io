<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Spark | Findhy's Blog]]></title>
  <link href="http://blog.findhy.com/blog/categories/spark/atom.xml" rel="self"/>
  <link href="http://blog.findhy.com/"/>
  <updated>2016-02-15T14:36:15+08:00</updated>
  <id>http://blog.findhy.com/</id>
  <author>
    <name><![CDATA[Findhy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Spark1.0在YARN上部署过程]]></title>
    <link href="http://blog.findhy.com/blog/2014/06/28/spark-on-yarn/"/>
    <updated>2014-06-28T14:13:34+08:00</updated>
    <id>http://blog.findhy.com/blog/2014/06/28/spark-on-yarn</id>
    <content type="html"><![CDATA[<p>Spark支持独立部署和在YARN上部署，选择在YARN上就是作为一个APP跑在YARN平台上，这样的好处是可以和原来的数据平台无缝结合。</p>

<!--more-->


<h3>安装过程</h3>

<p>1、下载</p>

<pre><code>wget https://github.com/apache/spark/archive/v1.0.0.zip
</code></pre>

<p>2、解压</p>

<pre><code>unzip v1.0.0.zip
</code></pre>

<p>3、进入目录</p>

<pre><code>cd spark-1.0.0
</code></pre>

<p>4、设置maven内存参数：</p>

<pre><code>export MAVEN_OPTS="-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m"
</code></pre>

<p>5、打包</p>

<pre><code>mvn -Pyarn-alpha -Dhadoop.version=2.0.0-cdh4.3.2 -DskipTests clean package
</code></pre>

<p>最后编译报错：</p>

<pre><code>Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (default) on project spark-core_2.10: An Ant BuildException has occured: Please set the SCALA_HOME (or SCALA_LIBRARY_PATH if scala is on the path) environment variables and retry.
[ERROR] around Ant part ...&lt;fail message="Please set the SCALA_HOME (or SCALA_LIBRARY_PATH if scala is on the path) environment variables and retry."&gt;... @ 6:126 in /home/hadoop/spark-cdh4.3.2/spark-1.0.0/core/target/antrun/build-main.xml
</code></pre>

<p>缺失scala的依赖</p>

<p>查看pom.xml</p>

<pre><code>&lt;scala.version&gt;2.10.4&lt;/scala.version&gt;
</code></pre>

<p>6、安装scala2.10.4</p>

<pre><code>wget http://www.scala-lang.org/files/archive/scala-2.10.4.tgz

tar -zxvf scala-2.10.4.tgz

export SCALA_HOME=/opt/scala/scala-2.10.4
</code></pre>

<p>7、再次打包</p>

<pre><code>mvn -Pyarn-alpha -Dhadoop.version=2.0.0-cdh4.3.2 -DskipTests clean package
</code></pre>

<p>这个打包过程需要很久，看到BUILD SUCCESS就成功了</p>

<p>8、打spark内核包</p>

<pre><code>SPARK_HADOOP_VERSION=2.0.0-cdh4.3.2 SPARK_YARN=true sbt/sbt assembly
</code></pre>

<p>9、执行完成之后，在YARN上发布APP</p>

<pre><code>./bin/spark-submit --class org.apache.spark.examples.SparkTC --master yarn-cluster --num-executors 3 --executor-memory 2g --driver-memory 4g --executor-cores 1 --jars /home/hadoop/spark-cdh4.3.2/spark-1.0.0/examples/target/spark-examples*.jar
</code></pre>

<p>看到命令行显示<br/>
<img src="/images/spark-1.png"></p>

<p>YARN管理台显示<br/>
<img src="/images/spark-2.png"></p>

<p>点击yarn app的tracking UI到达Spark的管理界面<br/>
<img src="/images/spark-3.png"></p>
]]></content>
  </entry>
  
</feed>

<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: IO | Findhy's Blog]]></title>
  <link href="http://findhy.com/blog/categories/io/atom.xml" rel="self"/>
  <link href="http://findhy.com/"/>
  <updated>2014-06-27T11:25:35+08:00</updated>
  <id>http://findhy.com/</id>
  <author>
    <name><![CDATA[Findhy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[存储性能瓶颈的成因、定位与排查]]></title>
    <link href="http://findhy.com/blog/2014/06/23/storage-performance-locate/"/>
    <updated>2014-06-23T10:41:46+08:00</updated>
    <id>http://findhy.com/blog/2014/06/23/storage-performance-locate</id>
    <content type="html"><![CDATA[<p>一个系统的性能瓶颈可能发生在很多地方，常见包括：CPU、内存、存储IO、网络、技术，其中存储IO的性能瓶颈最容易发生，往往我们刚开始搭建系统的时候都放在单台服务器上，当业务扩大后，单台已经无法支撑，常见的做法就是，前端加一个F5或者Nginx做负载均衡，后端应用做集群，数据库做集群或者读写分离、分表分库来缓解服务器的存储IO瓶颈，但是遇到存储瓶颈时我们如何定位问题和在架构设计的时候就去避免这样的问题呢，下面转载一篇EMC中文论坛的一篇文章，原文在这里<a href="https://community.emc.com/docs/DOC-34921">存储性能瓶颈的成因、定位与排查</a>。正文：</p>

<!--more-->


<h3>介绍</h3>

<p>企业数据存储性能瓶颈常常会发生在端口，控制器和磁盘，难点在于找出引起拥塞的单元，往往需要应用多重工具以及丰富的经验来查找并解决。
本文详细阐述存储瓶颈发生最常见的四种情况，可能发生的拥塞点，需要监控的参数指标，以及部署存储系统的最佳实践。</p>

<h3>更多信息</h3>

<h4>数据存储瓶颈的四个常见场景：</h4>

<p>以下是储瓶颈发生最常见的四种典型情况：</p>

<ol>
<li><p>当多个用户同时访问某一业务应用，无论是邮件服务器，企业资源规划（ERP）系统或数据库，数据请求会累积在队列中。单个I/O的响应时间开始增长，短暂延时开始转变成为漫长的等待。
这类响应时间敏感型应用的特征是，很多随机请求，读取比写入更多，I/O较小。最好的方法是：将负载分布在多块磁盘上，否则可能造成性能瓶颈。
如果应用增加了更多用户，或应用IOPS请求增加，则可能需要在RAID组中添加更多磁盘，或数据可能需要跨越更多磁盘，在更多层级做条带化。
存储在这样的情况下往往首先被怀疑，但大多数情况下并非存储引发，原因可能在于网络、应用或服务器。</p></li>
<li><p>带宽敏感型应用——如数据备份，视频流或安全登录，这类应用当多个用户同时访问大型文件或数据流时可能造成瓶颈。
定位这一问题存储管理员应当从备份服务器开始一路向下检查至磁盘，原因可能存在于这一通路的任何地方。
问题不一定发生在存储，可能是由于备份应用创建的方式或是磁带系统的工作方式引起的。如果瓶颈定位于存储，那么可能是由于服务I/O的磁盘数量不足，在控制器造成争用，或是阵列前端口带宽不足。
性能调优需要针对不同应用程序负载来完成。针对大型文件和流数据的调优并不适合于小型文件，反之亦然。这也就是为什么在大多数存储系统中往往做一个平衡，需要用户尝试并找出系统的折中。用户通常需要优化吞吐量或IOPS，但并不需要对两者同时优化。</p></li>
<li><p>RAID组中的磁盘故障。特别是在RAID 5中会造成性能的下降，因为系统需要重建校验数据。相比数据读写操作，重建会对性能造成更大影响。
即便坏盘是造成故障的根源，但控制器还是可能成为瓶颈，因为在重建过程中它需要不停地服务数据。当重建完成时，性能才会恢复正常。</p></li>
<li><p>部署了一种新的应用，而卷存在于处理繁忙邮件系统的同一磁盘。如果新的应用变得繁忙，邮件系统性能将会遭受影响。额外的流量最终会将磁盘完全覆盖。</p></li>
</ol>


<h4>存储瓶颈常发区域:</h4>

<h4>存储区域网络（Storage-area network, SAN）/阵列前端口</h4>

<p>存储部署于集中化SAN环境时，需考虑服务器和SAN之间的潜在网络瓶颈。例如，运行多部虚拟机的整合服务器可能不具备支持工作负载要求的足够网络端口。添加网络端口或转移网络密集型工作负载至其他服务器可解决这一问题。如前所述，对于带宽集中型应用，需考虑NFS有多少Fiber Channel 端口, or iSCSI 端口 or Ethernet 端口，需要用户站在带宽的角度来考量整个架构。</p>

<p>可能发生的问题包括：
如果阵列中端口数量不够，就会发生过饱和/过度使用。
虚拟服务器环境下的过量预定
端口间负载不均衡
交换机间链路争用/流量负荷过重
如某一HBA端口负载过重将导致HBA拥塞。使用虚拟机会导致问题更加严重。</p>

<h4>存储控制器</h4>

<p>一个标准的主动——被动或主动——主动控制器都有一个性能极限。接近这条上限取决于用户有多少块磁盘，因为每块磁盘的IOPS和吞吐量是固定的。</p>

<p>可能出现的问题包括：
控制器I/O过饱和，使得从缓存到阵列能够处理的IOPS受到限制
吞吐量“淹没“处理器
CPU过载/处理器功率不足
性能无法跟上SSD</p>

<h4>Cache</h4>

<p>由于服务器内存和CPU远比机械磁盘快得多，需为磁盘添加高速内存以缓存读写数据。例如，写入磁盘的数据存储在缓存中直到磁盘能够跟上，同时磁盘中的读数据放入缓存中直到能被主机读取。Cache比磁盘快1000倍，因此将数据写入和读出Cache对性能影响巨大。智能缓存算法能够预测你需要查找的数据，你是否会对此数据频繁访问，甚至是将访问频繁的随机数据放在缓存中。</p>

<p>可能发生的问题包括：
Cache memory不足
Cache写入过载，引起性能降低
频繁访问顺序性数据引起cache超负荷
Cache中需要持续不断地写入新数据，因此如果cache总是在refill，将无法从cache获益。</p>

<h4>磁盘</h4>

<p>磁盘瓶颈与磁盘转速有关, 慢速磁盘会引入较多延时。存储性能问题的排查首先考虑的因素就是磁盘速度，同时有多少块磁盘可进行并发读写。而另一因素是磁盘接口。采用更快的接口能够缓解磁盘瓶颈，但更重要的是在快速接口与相应更大的缓存大小以及转速之间取得平衡。同样，应避免将快速和慢速磁盘混入同一接口，因为慢速磁盘将会造成快速接口与快速磁盘的性能浪费。</p>

<p>可能引发的问题包括：
过多应用命中磁盘
磁盘数量不足以满足应用所需的IOPS或吞吐量
磁盘速度过慢无法满足性能需求及支持繁重工作负荷
Disk group往往是classic存储架构的潜在性能瓶颈，这种结构下RAID最多配置在16块磁盘。Thin结构通常每个LUN拥有更多磁盘，从而数据分布于更多spindle，因增加的并发性而减少了成为瓶颈的可能。</p>

<h4>需要监控的指标：</h4>

<p>曾经一度存储厂商们强调的是IOPS和吞吐量，但现在重点逐渐转变成为响应时间。也就是说，不是数据移动的速度有多快，而在于对请求的响应速度有多快。</p>

<p>正常情况下，15,000 rpm Fibre Channel磁盘响应时间为4ms，SAS磁盘响应时间约为5ms至6ms，SATA为10ms，而SSD少于1ms。如果发现Fibre Channel磁盘响应时间为12ms，或SSD响应时间变成5ms，那么就说明可能产生了争用，可能芯片发生了故障。</p>

<p>除了响应时间，其他需要监控的指标包括：
队列长度，队列中一次积累的请求数量，平均磁盘队列长度；
平均I/O大小千字节数；
IOPS （读和写，随机和顺序，整体平均IOPS）；
每秒百万字节吞吐量；
读写所占比例；
容量（空闲，使用和保留）。</p>

<h4>数据存储性能最佳实践：</h4>

<p>性能调优和改进的方式有很多种，用户当然可以通过添加磁盘，端口，多核处理器，内存来改善，但问题是：性价比，以及对业务是否实用。本文建议的方式是在预算范围内找寻性能最大化的解决方案。另外一个需要考虑的方面是环境并非一尘不变，系统部署方案要能够适应环境的改变需求。</p>

<p>首先需要考虑刷数据的性能特征，需要了解IO工作情况是怎样的。是否是cache友好型？是否是CPU集中型？业务数据很大数量很少，还是很小但数量很多？另外一方面就是构成存储环境的组件。包括应用，存储系统本身，网络。。。瓶颈可能在哪里，改善哪里最有效？</p>

<p>以下是一些常规建议：
不要仅仅根据空闲空间来分配存储，而需要结合考虑性能需求，确保为吞吐量或IOPS分配足够多的磁盘。
在磁盘间均衡分布应用负载，以减少热点地区的产生。
理解应用负载类型，并针对负载选择匹配的RAID类型。例如，写密集型应用建议使用RAID 1而不是RAID 5。因为当写入RAID 5时，需要计算校验位，需耗费较多时间。而RAID 1，写入两块磁盘速度快得多，无需计算。
磁盘类型（Fibre Channel, SAS, SATA）与期望性能相匹配。对于关键业务应用部署高性能磁盘，例如15,000 rpm Fibre Channel。
对于I/O密集型应用考虑采用SSD，但并不适用于写性能重要型应用。只要没有达到控制器瓶颈，SSD对读性能提升显著，但对写性能提升并没有明显效果。
采用端对端的监控工具，特别是虚拟服务器环境。虚拟端与物理端之间有一道防火墙，所以，需要穿透防火墙进行端到端的监控。
有些性能分析工具涵盖从应用到磁盘，有些仅局限于存储系统本身。由于性能是一个连锁反应包含很多变量，所以需要全面地分析数据。
以数据仅写入磁盘外部扇区的方式格式化磁盘。因减少数据定位时间而在高I/O环境下提升性能。负面作用是相当一部分磁盘容量未能得以使用。</p>

<h3>应用于</h3>

<p>存储性能分析、定位与排查</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[存储系统-I/O]]></title>
    <link href="http://findhy.com/blog/2014/03/16/io/"/>
    <updated>2014-03-16T15:40:50+08:00</updated>
    <id>http://findhy.com/blog/2014/03/16/io</id>
    <content type="html"><![CDATA[<p>存储系统瓶颈往往在于I/O，因此需要对I/O有一个整体而清晰的认识，也算是一次总结。I/O涉及的范围比较广，包括硬件架构和网络结构等方面，本篇文章试图从应用层面来分析：</p>

<!--more-->


<h2>1、性能参数</h2>

<p>I/O顾名思义就是数据输入和输出，在计算机中，不同的硬件或者介质I/O性能表现是不同的，下面是常见硬件性能参数。
<img src="/images/IO-1.png"><br/>
从上表可以看出，「千兆网络发送1MB数据」、「异地机房之间网络来回」、「SATA磁盘寻道」、「从SATA磁盘顺序读取1MB数据」是比较消耗时间的，都是10ms级别的。
因此我们在设计存储引擎的时候需要考虑如下因素：<strong>减少在网络间传输数据（特别是跨机架甚至跨机房）、减少发生磁盘寻道</strong>。</p>

<h2>2、案例分析</h2>

<p>所有的存储引擎在设计时候都需要根据业务需求（写多还是读多）设计解决方案来提高I/O效率。以HDFS为例来说明，看它是如何设计的。</p>

<h3>2.1、数据冗余策略</h3>

<p>Client申请将数据写入HDFS中，HDFS默认会将数据存3个副本（可以设置，默认为3）。<br/>
第一个副本放在Client所在的DataNode上（如果Client不在集群中，则随机选取一个负载较低的DataNode）<br/>
第二个副本放在与第一个副本节点不同机架中的DataNode（随机）<br/>
第三个副本放在与第二个副本节点同一个机架中另外一个DataNode节点（随机）</p>

<p>数据放在不同机架中是为了可靠性（机架的单点故障）。<br/>
后两个副本放在同一个机架是为了减少数据在网络节点中传输，看下图：
<img src="/images/IO-2.png"></p>

<h3>2.2、Combiner</h3>

<p>以HDFS为数据存储的基础之上，是MapReduce计算框架，分为两个阶段Map和Reduce，流程可以参考下图：<br/>
<img src="/images/IO-3.png"><br/>
数据在网络间传输发生在Shuffle阶段，Shuffle是指将Map输出的结果排序并按Key哈希分发到Reduce节点的过程，这个过程不可避免，所以只能尽量减少传输的数据量。
Combiner就是在Map端对数据进行一次本地Reduce，对数据量进行一次瘦身，但是必须保证对最终Reduce的结果没有影响，例如求最大值的MapReduce程序，只需要传输Map输出结果最大的那个值。</p>

<p>如何优化Shuffle减少传输的数据量是MapReduce优化的重点。例如Spark的Shuffle实现，可以参考<a href="http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/">这里</a>。</p>

<h3>2.3、HDFS块大小</h3>

<p>HDFS默认块大小是64MB，如果太小就会增加磁盘寻道的时间，如果太大造成Map执行时间过长，因为Map任务通常一次处理一个块的数据。所以块的大小设置直接影响MapReduce的性能。</p>

<h2>3、方法总结</h2>

<p>I/O优化策略可以简单的从上面两个方面来入手，同时需要结合相应的业务需求（<strong>系统吞吐量和响应时间、可用性（99.99）、一致性、可扩展性</strong>），来选择合适的解决方案。常见的优化手段有：</p>

<p><strong>成组提交</strong>：REDO日志先放在内存缓存区中，然后定期顺序写入磁盘，提供效率<br/>
<strong>checkpoint（检查点技术）</strong>：解决内存不足无法缓存所有的更新操作  <br/>
<strong>数据压缩</strong>：减少数据量，提高写入和传输速度。</p>
]]></content>
  </entry>
  
</feed>

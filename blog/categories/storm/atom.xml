<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Storm | Findhy's Blog]]></title>
  <link href="http://findhy.com/blog/categories/storm/atom.xml" rel="self"/>
  <link href="http://findhy.com/"/>
  <updated>2014-11-28T09:59:16+08:00</updated>
  <id>http://findhy.com/</id>
  <author>
    <name><![CDATA[Findhy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Storm与Kafka集成开发]]></title>
    <link href="http://findhy.com/blog/2014/06/16/storm-kafka-dev/"/>
    <updated>2014-06-16T16:44:35+08:00</updated>
    <id>http://findhy.com/blog/2014/06/16/storm-kafka-dev</id>
    <content type="html"><![CDATA[<p>项目源码在这里<a href="https://github.com/findhy/storm-kafka">storm-kafka</a>，里面包括了简单说明和测试过程，照着做就可以了，下面简单介绍一下。</p>

<p><img src="/images/storm-kafka-dev1.png"></p>

<!--more-->


<ul>
<li>数据源：该架构主要用来处理Streaming data，例子使用Wikipedia提供的Websocket接口，实时发送当前在Wikipedia网站编辑内容的用户相关信息</li>
<li>Websocket：可以参考这篇文章<a href="http://findhy.com/blog/2014/06/12/java-websocket/">Java-Websocket</a>，本框架使用Java语言作为kafka的客户端实现，所以也用的Java来实现Websocket，Kafka也支持其它语言作为client，这里是支持的客户端列表<a href="https://cwiki.apache.org/confluence/display/KAFKA/Clients">kafka-client</a>，用Node.js也是一个不错的选择</li>
<li>Storm：Storm与Kafka集成的重点在于Storm的Spout部分，这部分直接依赖这个库<a href="https://github.com/wurstmeister/storm-kafka-0.8-plus">storm-kafka-0.8-plus</a>，实现订阅Kafka的Topic</li>
<li>数据出口：Storm对Streaming data处理完了之后，一般会有两种出口，一是将数据持久化到HBase/Cassandra/Redis这样的NoSql Database中，二是通知前端在可视化界面上实时变动，该框架实现的是Storm将处理完的数据再次发送到Kafka中，前端通过Node.js和socket.io去订阅这个数据就可以(这部分暂未实现)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storm Spouts Lifecycle]]></title>
    <link href="http://findhy.com/blog/2014/06/10/storm-spouts-lifecycle/"/>
    <updated>2014-06-10T15:16:53+08:00</updated>
    <id>http://findhy.com/blog/2014/06/10/storm-spouts-lifecycle</id>
    <content type="html"><![CDATA[<p>Spouts是Storm中的Topology对应的消息生产者，消息将从Spouts发出，消息的单位是tuple，本文讲解Spouts核心方法以及Spouts方法的生命周期。相关接口方法看这里：<a href="http://storm.incubator.apache.org/apidocs/backtype/storm/spout/ISpout.html">ISpout</a>。Spouts在Storm中的位置可以参考下图：<br/>
<img src="/images/storm-concepts.png"></p>

<!--more-->


<h3>1.初始化</h3>

<p>当我们自定义一个Spouts的时候，继承BaseRichSpout类，代码是这样的：</p>

<pre><code>public class TestWordSpout extends BaseRichSpout{

    public static Logger LOG = LoggerFactory.getLogger(TestWordSpout.class);
    SpoutOutputCollector _collector;

    @Override
    public void open(Map conf, TopologyContext context,SpoutOutputCollector collector) {
        _collector = collector;
    }

    @Override
    public void nextTuple() {

    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {

    }

}
</code></pre>

<p>BaseRichSpout是Storm提供的一个抽象类，代码如下：</p>

<pre><code>/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package backtype.storm.topology.base;

import backtype.storm.topology.IRichSpout;

/**
 *
 * @author nathan
 */
public abstract class BaseRichSpout extends BaseComponent implements IRichSpout {
    @Override
    public void close() {
    }

    @Override
    public void activate() {
    }

    @Override
    public void deactivate() {
    }

    @Override
    public void ack(Object msgId) {
    }

    @Override
    public void fail(Object msgId) {
    }
}
</code></pre>

<p>可以看到BaseRichSpout没有做任何事情就是实现了接口的方法，没有任何具体实现，这样子类不用显式实现方法了，它继承了BaseComponent，实现了接口IRichSpout，而IRichSpout接口是继承自ISpout, IComponent这两个接口，BaseComponent类如下：</p>

<pre><code>package backtype.storm.topology.base;

import backtype.storm.topology.IComponent;
import java.util.Map;

public abstract class BaseComponent implements IComponent {
    @Override
    public Map&lt;String, Object&gt; getComponentConfiguration() {
        return null;
    }
}
</code></pre>

<p>可以看到BaseComponent只是实现了接口的方法getComponentConfiguration()返回null。   <br/>
下面来看下ISpout, IComponent这两个接口</p>

<pre><code>package backtype.storm.topology;

import java.io.Serializable;
import java.util.Map;

public interface IComponent extends Serializable {

    void declareOutputFields(OutputFieldsDeclarer declarer);

    Map&lt;String, Object&gt; getComponentConfiguration();

}

package backtype.storm.spout;

import backtype.storm.task.TopologyContext;
import java.util.Map;
import java.io.Serializable;

public interface ISpout extends Serializable {

    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);

    void close();

    void activate();

    void deactivate();

    void nextTuple();

    void ack(Object msgId);

    void fail(Object msgId);
}
</code></pre>

<p>上面把javadoc都去掉，如果要看的话直接看源码，或者到这里看：<a href="http://storm.incubator.apache.org/apidocs  ">http://storm.incubator.apache.org/apidocs  </a>
到这里基本可以看到核心的接口方法主要在IComponent和ISpou这两个接口中定义，下面详细讲解。</p>

<h3>2.IComponent接口方法详解</h3>

<p>IComponent接口是topology中所有组件的顶层接口，包括Spouts、Bolts，它定义了两个核心的公共方法：</p>

<pre><code>    /**
     * 该方法是用来定义topology中的spout或者bolt的ID，而且该ID在同是spouts或者bolts内部不能重复，但是spouts和bolts之间的ID可以重复
     * 如果没有显示指定该值，则默认使用Utils.DEFAULT_STREAM_ID这个值
     * 这里可以参考Storm源码TopologyBuilder类里面的validateUnusedId这个方法
     * 
     * 该方法在客户端调用createTopology()方法时被执行，同样参见TopologyBuilder类
     * 
     * 源码：https://github.com/nathanmarz/storm/blob/moved-to-apache/storm-core/src/jvm/backtype/storm/topology/TopologyBuilder.java#L226
     */
    void declareOutputFields(OutputFieldsDeclarer declarer);

    /**
     * 该方法可以用来配置组件
     * 
     * Declare configuration specific to this component. Only a subset of the "topology.*" configs can
     * be overridden. The component configuration can be further overridden when constructing the 
     * topology using {@link TopologyBuilder}
     *
     */
    Map&lt;String, Object&gt; getComponentConfiguration();
</code></pre>

<h3>3.ISpout接口方法详解</h3>

<pre><code>    /**
     * 该方法在task任务组件在worker里初始化的时候被调用，它提供了spout的执行环境
     * Called when a task for this component is initialized within a worker on the cluster.
     * It provides the spout with the environment in which the spout executes.
     *
     * &lt;p&gt;This includes the:&lt;/p&gt;
     *
     * @param conf The Storm configuration for this spout. This is the configuration 
     * provided to the topology merged in with cluster configuration on this machine.
     * @param context This object can be used to get information about this task's place 
     * within the topology, including the task id and component id of this task, input 
     * and output information, etc.
     * 
     * @param collector The collector is used to emit tuples from this spout. 
     * Tuples can be emitted at any time, including the open and close methods. 
     * The collector is thread-safe and should be saved as an instance variable of this spout object.
     */
    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);

    /**
     * Spout停掉的时候会调用此方法
     * 
     * Called when an ISpout is going to be shutdown. There is no guarentee that close
     * will be called, because the supervisor kill -9's worker processes on the cluster.
     *
     * &lt;p&gt;The one context where close is guaranteed to be called is a topology is
     * killed when running Storm in local mode.&lt;/p&gt;
     */
    void close();

    /**
     * spout由deactivated模式转为activated模式时被调用
     * 
     * Called when a spout has been activated out of a deactivated mode.
     * nextTuple will be called on this spout soon. A spout can become activated
     * after having been deactivated when the topology is manipulated using the 
     * `storm` client. 
     */
    void activate();

    /**
     * spout被deactivated的时候调用，并且当spout被deactivated时，nextTuple就不会被调用了
     * 
     * Called when a spout has been deactivated. nextTuple will not be called while
     * a spout is deactivated. The spout may or may not be reactivated in the future.
     */
    void deactivate();

    /**
     * spout发射Tuple时被调用，该方法必须是非阻塞的（non-blocking），这样如果Spout没有tuples可以发射了，
     * 这个方法也会返回，nextTuple, ack, and fail这几个方法在同一个spout task同一个线程里面是会被循环调用的，
     * 当没有tuples可以发射了，应该让线程sleep一段时间
     * 这样就不会占用太多的CPU资源了
     * 
     * When this method is called, Storm is requesting that the Spout emit tuples to the 
     * output collector. This method should be non-blocking, so if the Spout has no tuples
     * to emit, this method should return. nextTuple, ack, and fail are all called in a tight
     * loop in a single thread in the spout task. When there are no tuples to emit, it is courteous
     * to have nextTuple sleep for a short amount of time (like a single millisecond)
     * so as not to waste too much CPU.
     */
    void nextTuple();

    /**
     * Storm可以保证spout发射出去的tuples必须被处理了，msgId就是就是发射的消息的ID
     * 当tuples被处理完了之后，该方法会被调用，并且将它从队列中去掉防止被反复处理
     * 
     * Storm has determined that the tuple emitted by this spout with the msgId identifier
     * has been fully processed. Typically, an implementation of this method will take that
     * message off the queue and prevent it from being replayed.
     */
    void ack(Object msgId);

    /**
     * 如果msgId对应的tuples处理失败，该方法会被调用，通常的实现会将tuples重新放回队列，让它多一段时间可以被处理
     * 上面两个方法ack和fail是Storm保证数据一定被处理和避免重复处理的机制，
     * 参数msgId就是每次发射tuples的时候spout提供的一个
     * message-id，后面可以通过这个message-id来追踪这个tuple
     * 
     * The tuple emitted by this spout with the msgId identifier has failed to be
     * fully processed. Typically, an implementation of this method will put that
     * message back on the queue to be replayed at a later time.
     */
    void fail(Object msgId);
</code></pre>

<h3>4.总结</h3>

<ul>
<li>客户端提交Topology的时候，首先调用declareOutputFields(&hellip;)方法，指定spout和bolt的ID，如果没有实现该方法则默认为Utils.DEFAULT_STREAM_ID</li>
<li>然后Storm会在worker进程内初始化task的运行环境，再调用open(&hellip;)方法，传回SpoutOutputCollector对象，后面我们后可以SpoutOutputCollector来发射tuples</li>
<li>然后Storm就会反复调用spout的nextTuple方法获取下一个tuple，如果任务处理成功了就调用ack方法，如果任务处理失败就调用fail方法</li>
<li>并且Spout发射tuple会提供一个message-id，后面我们通过这个message-id来追踪这个tuple，ack和fail接受的参数就是该message-id</li>
<li>一个tuple可能会产生多个tuple，最终形成一个tuple树，Storm会跟踪整个tuple树，如果其中一个叶子tuple失败，那么整个tuple树会重新被处理</li>
<li>值得注意的一点是，storm调用ack或者fail的task始终是产生这个tuple的那个task。所以如果一个spout被分成很多个task来执行， 消息执行的成功失败与否始终会通知最开始发出tuple的那个task</li>
<li>每个你处理的tuple， 必须被ack或者fail。因为storm追踪每个tuple要占用内存。所以如果你不ack/fail每一个tuple， 那么最终你会看到OutOfMemory错误。</li>
</ul>


<p>本文参考：<br/>
<a href="http://xumingming.sinaapp.com/127/twitter-storm%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/">Storm如何保证消息不丢失</a><br/>
<a href="http://stackoverflow.com/questions/21689059/with-storm-spouts-when-is-declareoutputfields-called">storm-spouts</a><br/>
<a href="http://storm.incubator.apache.org/apidocs">storm-javadocs</a><br/>
<a href="http://xumingming.sinaapp.com/117/twitter-storm%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%B3%E9%94%AE%E6%A6%82%E5%BF%B5/">storm的一些关键概念</a><br/>
<a href="http://xumingming.sinaapp.com/138/twitter-storm%E5%85%A5%E9%97%A8/">storm入门</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storm-on-YARN Install]]></title>
    <link href="http://findhy.com/blog/2014/05/17/storm-on-yarn/"/>
    <updated>2014-05-17T06:37:52+08:00</updated>
    <id>http://findhy.com/blog/2014/05/17/storm-on-yarn</id>
    <content type="html"><![CDATA[<p>Storm是一个流数据的实时计算框架，可以单独部署也可是部署在YARN上，本篇文章主要讲解Storm如何部署在YARN上面。  当然前提是Hadoop2.X已经装上了，然后需要安装Zookeeper来作为Storm集群的分布式协调服务。</p>

<!--more-->


<p>环境说明</p>

<pre><code>master 10.0.1.252  
slave1 10.0.1.252  
slave2 10.0.1.252  
</code></pre>

<p>软件版本</p>

<pre><code>https://github.com/anfeng/storm-yarn/archive/master.zip  
Storm-0.9.0-win21  
zookeeper-3.4.5-cdh5.0.0-beta-2  
apache-maven-3.1.0  
</code></pre>

<h2>Zookeeper集群搭建</h2>

<hr />

<p>Storm需要使用zookeeper来协调整个集群，但是storm并不用zookeeper来传递消息，所以zookeeper的负载很低，大多数情况下，单个节点的zookeeper就够了，所以我们这里就只部署一台机子的zookeeper，后面再扩展到集群。</p>

<h3>1.安装JDK</h3>

<p>前面Hadoop集群已经安装了，只要保证JDK版本在1.6以上就可以了。</p>

<h3>2.下载和解压zookeeper安装包</h3>

<p>因为我们用的是CDH的Hadoop发行版，所以这里zookeeper也用CDH的，到这里下载：</p>

<pre><code>wget http://archive-primary.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.0.0-beta-2.tar.gz
</code></pre>

<p>解压</p>

<pre><code>tar –zxvf zookeeper-3.4.5-cdh5.0.0-beta-2.tar.gz
</code></pre>

<h3>3.修改zoo.cfg配置文件</h3>

<p>进入zookeeper安装目录/home/hadoop/zookeeper-3.4.5-cdh5.0.0-beta-2/conf，将zoo_sample.cfg重命名为zoo.cfg</p>

<pre><code>mv zoo_sample.cfg zoo.cfg
</code></pre>

<p>修改zoo.cfg文件，增加：</p>

<pre><code>tickTime=2000
dataDir=/home/hadoop/zookeeper-data
clientPort=2181
initLimit=5
syncLimit=2
server.1=master:2888:3888
</code></pre>

<p>创建这个目录：/home/hadoop/zookeeper-data</p>

<h3>4.修改myid</h3>

<p>在/home/hadoop/zookeeper-data目录下创建文件myid，里面内容为server的ID，这里写：1</p>

<h3>5.配置zookeeper的环境变量</h3>

<p>vi /etc/profile，增加：</p>

<pre><code>export ZOOKEEPER_HOME=/home/hadoop/zookeeper-3.4.5-cdh5.0.0-beta-2
export PATH=$PATH:$ZOOKEEPER_HOME/bin

source /etc/profile
</code></pre>

<h3>6.启动zookeeper</h3>

<pre><code>./bin/zkServer.sh start
</code></pre>

<h3>7.测试Zookeeper</h3>

<p>测试Zookeeper客户端是否可用</p>

<pre><code>./bin/zkCli.sh -server 127.0.0.1:2181
</code></pre>

<p>测试结果，看到进入到了zookeeper的命令行就是成功了：</p>

<h2>Storm-on-YARN搭建</h2>

<hr />

<h3>1.安装maven</h3>

<p>下载maven安装包</p>

<pre><code>wget http://archive.apache.org/dist/maven/maven-3/3.1.0/binaries/apache-maven-3.1.0-bin.tar.gz
</code></pre>

<p>解压</p>

<pre><code>tar –zxvf apache-maven-3.1.0-bin.tar.gz
</code></pre>

<h3>2.配置环境变量</h3>

<pre><code>vi /etc/profile
</code></pre>

<p>添加：</p>

<pre><code>export MAVEN_HOME=/home/hadoop/apache-maven-3.1.0
export PATH=$PATH:$MAVEN_HOME/bin
</code></pre>

<p>使环境变量生效：</p>

<pre><code>source /etc/profile
</code></pre>

<p>测试</p>

<pre><code>mvn –version
</code></pre>

<h3>3.下载storm on yarn</h3>

<p>这里下载@anfeng的分支版本（针对Hadoop2.2.0的），而不是官方版本。</p>

<pre><code>wget https://github.com/anfeng/storm-yarn/archive/master.zip
</code></pre>

<p>解压：</p>

<pre><code>unzip master
</code></pre>

<p>解压完了会生成一个storm-yarn-master目录</p>

<h3>4.编译storm on yarn</h3>

<p>进入storm-yarn-master目录：</p>

<pre><code>cd storm-yarn-master
</code></pre>

<p>编译（跳过测试）：</p>

<pre><code>mvn package –DskipTests
</code></pre>

<h3>5.在HDFS中创建对应Storm目录</h3>

<p>在HDFS中创建目录：</p>

<pre><code>/lib/storm/0.9.0-wip21
</code></pre>

<h3>6.将storm.zip放进去（注意和你自己的目录对应）</h3>

<pre><code>./bin/hadoop fs -put /home/hadoop/storm-yarn-master/lib/storm.zip /lib/storm/0.9.0-wip21/
</code></pre>

<h3>7.解压Storm</h3>

<p>将/home/hadoop/storm-yarn-master/lib /storm-0.9.0-wip21.zip
解压到/home/hadoop/storm-yarn-master这个目录下</p>

<h3>8.修改环境变量</h3>

<pre><code>export STORM_HOME=/home/hadoop/storm-yarn-master
export PATH=$PATH:$STORM_HOME/storm-0.9.0-wip21/bin
export PATH=$PATH:$STORM_HOME/bin
</code></pre>

<p>环境变量生效：</p>

<pre><code>source /etc/profile
</code></pre>

<h3>9.修改storm.yaml</h3>

<p>修改/home/hadoop/storm-yarn-master/storm-0.9.0-wip21/conf/storm.yaml配置文件，增加zookeeper的配置：</p>

<pre><code>storm.zookeeper.servers:
  - "master"
</code></pre>

<h3>10.启动storm on yarn环境</h3>

<p>执行下面命令启动：</p>

<pre><code>storm-yarn launch storm.yaml
</code></pre>

<p>如果报错：yarn is not installed
设置Hadoop和YARN的环境变量（如果已经设置过了请跳过这一步）</p>

<pre><code>export HADOOP_DEV_HOME=/home/hadoop/hadoop-2.2.0-cdh5.0.0-beta-2
export PATH=$PATH:$HADOOP_DEV_HOME/bin
export PATH=$PATH:$HADOOP_DEV_HOME/sbin
export HADOOP_MAPARED_HOME=${HADOOP_DEV_HOME}
export HADOOP_COMMON_HOME=${HADOOP_DEV_HOME}
export HADOOP_HDFS_HOME=${HADOOP_DEV_HOME}
export YARN_HOME=${HADOOP_DEV_HOME}
export HADOOP_CONF_DIR=${HADOOP_DEV_HOME}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_DEV_HOME}/etc/hadoop
export YARN_CONF_DIR=${HADOOP_DEV_HOME}/etc/Hadoop

source /etc/profile
</code></pre>

<p>再试一下</p>

<pre><code>storm-yarn launch storm.yaml
</code></pre>

<p>因为storm是作为一个yarn程序运行在集群上的，所以在YARN的集群管理页面中会有一个AppId</p>

<h3>11.复制storm.yaml</h3>

<p>创建这个目录：~/.storm
执行（appid换成上面YARN管理界面中看到的appid）：</p>

<pre><code>storm-yarn getStormConfig -appId application_1399464020057_0006  -output ~/.storm/storm.yaml
</code></pre>

<h3>12.查看nimbus</h3>

<p>执行下面命令确定nimbus.host</p>

<pre><code>cat ~/.storm/storm.yaml | grep nimbus.host  
</code></pre>

<h3>13.提交Topology</h3>

<p>注意nimbus.host就是上面查询的nimbus服务器</p>

<pre><code>storm jar ./lib/storm-starter-0.0.1-SNAPSHOT.jar storm.starter.WordCountTopology WordCountTopology -c nimbus.host=10.0.1.253
</code></pre>

<h3>14.Storm监控</h3>

<p>看一下storm的UI监控界面（nimbus.host:7070），可以看见刚刚提交的wordcountTopology</p>

<pre><code>http://nimbus.host:7070/
</code></pre>

<h3>15.YARN-Storm Client</h3>

<p>现在Storm作为一个应用部署在YARN上，后面所有Storm集群的控制都可以通过YARN客户端命令来完成，下面简单介绍一下。构建一个Storm的集群命令</p>

<pre><code>storm-yarn launch &lt;storm-yarn-config&gt;  
</code></pre>

<p>其中，&lt;storm-yarn-config>是Storm的配置信息，包括启动Supervisor个数，Storm ApplicationMaster占用的内存等。</p>

<p>启动Storm后，可以通过下面的命令来控制Storm：</p>

<pre><code>storm-yarn [command] –appId [appId] –output [file] [–supervisors [n]]
</code></pre>

<p>其中，command为具体命令，具体参见下面两张表，参数 –appId 为启动的Storm在YARN中的应用程序ID，通过YANR的集群管理界面可以看见，-Supervisors为需要增加的Supervisor服务个数，该参数只对命令addSupervisors有效。
例如我们现在增加2个Supervisors，命令如下：</p>

<pre><code>storm-yarn addSupervisors -appId application_1399464020057_0006 -supervisors 2
</code></pre>

<p>输入storm-yarn查看所有命令</p>

<h3>16.关闭Storm on yarn集群</h3>

<pre><code>storm-yarn shutdown –appId [applicationId]
</code></pre>

<h2>参考</h2>

<p><a href="http://dongxicheng.org/mapreduce-nextgen/storm-on-yarn/">http://dongxicheng.org/mapreduce-nextgen/storm-on-yarn/</a></p>

<p><a href="http://www.geedoo.info/storm-on-yarn-platform-to-build.html">http://www.geedoo.info/storm-on-yarn-platform-to-build.html</a></p>

<p><a href="http://blog.csdn.net/weijonathan/article/details/17762477">http://blog.csdn.net/weijonathan/article/details/17762477</a></p>

<p><a href="https://xumingming.sinaapp.com/179/twitter-storm-%E6%90%AD%E5%BB%BAstorm%E9%9B%86%E7%BE%A4/">https://xumingming.sinaapp.com/179/twitter-storm-%E6%90%AD%E5%BB%BAstorm%E9%9B%86%E7%BE%A4/</a></p>

<p><a href="http://yzprofile.me/2013/04/25/storm-tutorial.html">http://yzprofile.me/2013/04/25/storm-tutorial.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storm Introduction]]></title>
    <link href="http://findhy.com/blog/2014/04/17/storm/"/>
    <updated>2014-04-17T22:54:04+08:00</updated>
    <id>http://findhy.com/blog/2014/04/17/storm</id>
    <content type="html"><![CDATA[<h1>使用场景</h1>

<p>Storm可以通过插件运行在Hadoop YARN平台上，由YARN统一调度实现资源的共享。Storm可以使用任何语言来写topologies。</p>

<p>下面五个特性保证了Storm实时处理的能力：</p>

<!--more-->


<ul>
<li><strong>Fast</strong> &ndash; 快，每个节点每秒可以处理百万个100字节的消息</li>
<li><strong>Scalable</strong> &ndash; 可扩展，这没得说</li>
<li><strong>Fault-tolerant</strong> &ndash; 容错，如果workers进程死掉，Storm会自动重启。如果一个节点死掉，会在其它节点上重启workers进程</li>
<li><strong>Reliable</strong> &ndash; 可靠性，Storm确保每个单元数据（tuple）会被处理最少一次，仅仅当消息处理失败才会发生通知</li>
<li><strong>Easy to operate</strong> &ndash; 标准的配置适应于生产环境，一旦部署，Storm很容易操作。</li>
</ul>


<h1>Storm架构</h1>

<p>一个Storm集群应该包含下面三类节点</p>

<ul>
<li><strong>Nimbus Node</strong> &ndash; master节点，相当于Hadoop集群的JobTracker，负责：Uploads computations for execution（不懂）、在集群中分发代码、负责在集群中启动workers进程、监控计算资源如果需要会重新分配workers进程</li>
<li><strong>ZooKeeper Nodes</strong> &ndash; 负责协调Storm集群，当然也可以由YARN平台来管理</li>
<li><strong>Supervisor Nodes</strong> &ndash; 通过Zookeeper或者YARN与Nimbus节点通信，根据Nimbus返回的消息来启动和停止workers进程</li>
</ul>


<p><img src="/images/storm_0.png"></p>

<p>通过下面5个关键点来理解Storm是如何处理数据的：</p>

<ul>
<li><strong>Tuples</strong> &ndash; 元素的有序列表，例如“4-tuple”可能是（7,1,3,7）</li>
<li><strong>Streams</strong> &ndash; 一个没有边界的tuples序列</li>
<li><strong>Spouts</strong> &ndash; 集群中传输的计算资源（例如 Twitter API）</li>
<li><strong>Bolts</strong> &ndash; 处理输入输出流，可以：启动函数、过滤器、统计或合并数据，或访问数据库</li>
<li><strong>Topologies</strong> &ndash; 由Spouts和Bolts组成的网络结构</li>
</ul>


<p><img src="/images/storm_1.png"></p>

<p>数据由spout输入，由bolt处理，然后存入Hadoop中。</p>

<p>更多请访问<a href="http://zh.hortonworks.com/labs/storm/">这里</a></p>

<p>可以从<a href="http://zh.hortonworks.com/hadoop-tutorial/processing-streaming-data-near-real-time-apache-storm/">这里</a>开始练习。</p>
]]></content>
  </entry>
  
</feed>

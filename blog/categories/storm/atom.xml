<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Storm | Findhy's Blog]]></title>
  <link href="http://findhy.com/blog/categories/storm/atom.xml" rel="self"/>
  <link href="http://findhy.com/"/>
  <updated>2014-06-07T15:02:22+08:00</updated>
  <id>http://findhy.com/</id>
  <author>
    <name><![CDATA[Findhy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Storm-on-YARN安装说明]]></title>
    <link href="http://findhy.com/blog/2014/05/17/storm-on-yarn/"/>
    <updated>2014-05-17T06:37:52+08:00</updated>
    <id>http://findhy.com/blog/2014/05/17/storm-on-yarn</id>
    <content type="html"><![CDATA[<p>Storm是一个流数据的实时计算框架，可以单独部署也可是部署在YARN上，本篇文章主要讲解Storm如何部署在YARN上面。  当然前提是Hadoop2.X已经装上了，然后需要安装Zookeeper来作为Storm集群的分布式协调服务。</p>

<p>环境说明</p>

<pre><code>master 10.0.1.252  
slave1 10.0.1.252  
slave2 10.0.1.252  
</code></pre>

<p>软件版本</p>

<pre><code>https://github.com/anfeng/storm-yarn/archive/master.zip  
Storm-0.9.0-win21  
zookeeper-3.4.5-cdh5.0.0-beta-2  
apache-maven-3.1.0  
</code></pre>

<h2>Zookeeper集群搭建</h2>

<hr />

<p>Storm需要使用zookeeper来协调整个集群，但是storm并不用zookeeper来传递消息，所以zookeeper的负载很低，大多数情况下，单个节点的zookeeper就够了，所以我们这里就只部署一台机子的zookeeper，后面再扩展到集群。</p>

<h3>1.安装JDK</h3>

<p>前面Hadoop集群已经安装了，只要保证JDK版本在1.6以上就可以了。</p>

<h3>2.下载和解压zookeeper安装包</h3>

<p>因为我们用的是CDH的Hadoop发行版，所以这里zookeeper也用CDH的，到这里下载：</p>

<pre><code>wget http://archive-primary.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.0.0-beta-2.tar.gz
</code></pre>

<p>解压</p>

<pre><code>tar –zxvf zookeeper-3.4.5-cdh5.0.0-beta-2.tar.gz
</code></pre>

<h3>3.修改zoo.cfg配置文件</h3>

<p>进入zookeeper安装目录/home/hadoop/zookeeper-3.4.5-cdh5.0.0-beta-2/conf，将zoo_sample.cfg重命名为zoo.cfg</p>

<pre><code>mv zoo_sample.cfg zoo.cfg
</code></pre>

<p>修改zoo.cfg文件，增加：</p>

<pre><code>tickTime=2000
dataDir=/home/hadoop/zookeeper-data
clientPort=2181
initLimit=5
syncLimit=2
server.1=master:2888:3888
</code></pre>

<p>创建这个目录：/home/hadoop/zookeeper-data</p>

<h3>4.修改myid</h3>

<p>在/home/hadoop/zookeeper-data目录下创建文件myid，里面内容为server的ID，这里写：1</p>

<h3>5.配置zookeeper的环境变量</h3>

<p>vi /etc/profile，增加：</p>

<pre><code>export ZOOKEEPER_HOME=/home/hadoop/zookeeper-3.4.5-cdh5.0.0-beta-2
export PATH=$PATH:$ZOOKEEPER_HOME/bin

source /etc/profile
</code></pre>

<h3>6.启动zookeeper</h3>

<pre><code>./bin/zkServer.sh start
</code></pre>

<h3>7.测试Zookeeper</h3>

<p>测试Zookeeper客户端是否可用</p>

<pre><code>./bin/zkCli.sh -server 127.0.0.1:2181
</code></pre>

<p>测试结果，看到进入到了zookeeper的命令行就是成功了：</p>

<!--more-->


<h2>Storm-on-YARN搭建</h2>

<hr />

<h3>1.安装maven</h3>

<p>下载maven安装包</p>

<pre><code>wget http://archive.apache.org/dist/maven/maven-3/3.1.0/binaries/apache-maven-3.1.0-bin.tar.gz
</code></pre>

<p>解压</p>

<pre><code>tar –zxvf apache-maven-3.1.0-bin.tar.gz
</code></pre>

<h3>2.配置环境变量</h3>

<pre><code>vi /etc/profile
</code></pre>

<p>添加：</p>

<pre><code>export MAVEN_HOME=/home/hadoop/apache-maven-3.1.0
export PATH=$PATH:$MAVEN_HOME/bin
</code></pre>

<p>使环境变量生效：</p>

<pre><code>source /etc/profile
</code></pre>

<p>测试</p>

<pre><code>mvn –version
</code></pre>

<h3>3.下载storm on yarn</h3>

<p>这里下载@anfeng的分支版本（针对Hadoop2.2.0的），而不是官方版本。</p>

<pre><code>wget https://github.com/anfeng/storm-yarn/archive/master.zip
</code></pre>

<p>解压：</p>

<pre><code>unzip master
</code></pre>

<p>解压完了会生成一个storm-yarn-master目录</p>

<h3>4.编译storm on yarn</h3>

<p>进入storm-yarn-master目录：</p>

<pre><code>cd storm-yarn-master
</code></pre>

<p>编译（跳过测试）：</p>

<pre><code>mvn package –DskipTests
</code></pre>

<h3>5.在HDFS中创建对应Storm目录</h3>

<p>在HDFS中创建目录：</p>

<pre><code>/lib/storm/0.9.0-wip21
</code></pre>

<h3>6.将storm.zip放进去（注意和你自己的目录对应）</h3>

<pre><code>./bin/hadoop fs -put /home/hadoop/storm-yarn-master/lib/storm.zip /lib/storm/0.9.0-wip21/
</code></pre>

<h3>7.解压Storm</h3>

<p>将/home/hadoop/storm-yarn-master/lib /storm-0.9.0-wip21.zip
解压到/home/hadoop/storm-yarn-master这个目录下</p>

<h3>8.修改环境变量</h3>

<pre><code>export STORM_HOME=/home/hadoop/storm-yarn-master
export PATH=$PATH:$STORM_HOME/storm-0.9.0-wip21/bin
export PATH=$PATH:$STORM_HOME/bin
</code></pre>

<p>环境变量生效：</p>

<pre><code>source /etc/profile
</code></pre>

<h3>9.修改storm.yaml</h3>

<p>修改/home/hadoop/storm-yarn-master/storm-0.9.0-wip21/conf/storm.yaml配置文件，增加zookeeper的配置：</p>

<pre><code>storm.zookeeper.servers:
  - "master"
</code></pre>

<h3>10.启动storm on yarn环境</h3>

<p>执行下面命令启动：</p>

<pre><code>storm-yarn launch storm.yaml
</code></pre>

<p>如果报错：yarn is not installed
设置Hadoop和YARN的环境变量（如果已经设置过了请跳过这一步）</p>

<pre><code>export HADOOP_DEV_HOME=/home/hadoop/hadoop-2.2.0-cdh5.0.0-beta-2
export PATH=$PATH:$HADOOP_DEV_HOME/bin
export PATH=$PATH:$HADOOP_DEV_HOME/sbin
export HADOOP_MAPARED_HOME=${HADOOP_DEV_HOME}
export HADOOP_COMMON_HOME=${HADOOP_DEV_HOME}
export HADOOP_HDFS_HOME=${HADOOP_DEV_HOME}
export YARN_HOME=${HADOOP_DEV_HOME}
export HADOOP_CONF_DIR=${HADOOP_DEV_HOME}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_DEV_HOME}/etc/hadoop
export YARN_CONF_DIR=${HADOOP_DEV_HOME}/etc/Hadoop

source /etc/profile
</code></pre>

<p>再试一下</p>

<pre><code>storm-yarn launch storm.yaml
</code></pre>

<p>因为storm是作为一个yarn程序运行在集群上的，所以在YARN的集群管理页面中会有一个AppId</p>

<h3>11.复制storm.yaml</h3>

<p>创建这个目录：~/.storm
执行（appid换成上面YARN管理界面中看到的appid）：</p>

<pre><code>storm-yarn getStormConfig -appId application_1399464020057_0006  -output ~/.storm/storm.yaml
</code></pre>

<h3>12.查看nimbus</h3>

<p>执行下面命令确定nimbus.host</p>

<pre><code>cat ~/.storm/storm.yaml | grep nimbus.host  
</code></pre>

<h3>13.提交Topology</h3>

<p>注意nimbus.host就是上面查询的nimbus服务器</p>

<pre><code>storm jar ./lib/storm-starter-0.0.1-SNAPSHOT.jar storm.starter.WordCountTopology WordCountTopology -c nimbus.host=10.0.1.253
</code></pre>

<h3>14.Storm监控</h3>

<p>看一下storm的UI监控界面（nimbus.host:7070），可以看见刚刚提交的wordcountTopology</p>

<pre><code>http://nimbus.host:7070/
</code></pre>

<h3>15.YARN-Storm Client</h3>

<p>现在Storm作为一个应用部署在YARN上，后面所有Storm集群的控制都可以通过YARN客户端命令来完成，下面简单介绍一下。构建一个Storm的集群命令</p>

<pre><code>storm-yarn launch &lt;storm-yarn-config&gt;  
</code></pre>

<p>其中，&lt;storm-yarn-config>是Storm的配置信息，包括启动Supervisor个数，Storm ApplicationMaster占用的内存等。</p>

<p>启动Storm后，可以通过下面的命令来控制Storm：</p>

<pre><code>storm-yarn [command] –appId [appId] –output [file] [–supervisors [n]]
</code></pre>

<p>其中，command为具体命令，具体参见下面两张表，参数 –appId 为启动的Storm在YARN中的应用程序ID，通过YANR的集群管理界面可以看见，-Supervisors为需要增加的Supervisor服务个数，该参数只对命令addSupervisors有效。
例如我们现在增加2个Supervisors，命令如下：</p>

<pre><code>storm-yarn addSupervisors -appId application_1399464020057_0006 -supervisors 2
</code></pre>

<p>输入storm-yarn查看所有命令</p>

<h3>16.关闭Storm on yarn集群</h3>

<pre><code>storm-yarn shutdown –appId [applicationId]
</code></pre>

<h2>参考</h2>

<p><a href="http://dongxicheng.org/mapreduce-nextgen/storm-on-yarn/">http://dongxicheng.org/mapreduce-nextgen/storm-on-yarn/</a></p>

<p><a href="http://www.geedoo.info/storm-on-yarn-platform-to-build.html">http://www.geedoo.info/storm-on-yarn-platform-to-build.html</a></p>

<p><a href="http://blog.csdn.net/weijonathan/article/details/17762477">http://blog.csdn.net/weijonathan/article/details/17762477</a></p>

<p><a href="https://xumingming.sinaapp.com/179/twitter-storm-%E6%90%AD%E5%BB%BAstorm%E9%9B%86%E7%BE%A4/">https://xumingming.sinaapp.com/179/twitter-storm-%E6%90%AD%E5%BB%BAstorm%E9%9B%86%E7%BE%A4/</a></p>

<p><a href="http://yzprofile.me/2013/04/25/storm-tutorial.html">http://yzprofile.me/2013/04/25/storm-tutorial.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storm Introduction]]></title>
    <link href="http://findhy.com/blog/2014/04/17/storm/"/>
    <updated>2014-04-17T22:54:04+08:00</updated>
    <id>http://findhy.com/blog/2014/04/17/storm</id>
    <content type="html"><![CDATA[<h1>使用场景</h1>

<p>Storm可以通过插件运行在Hadoop YARN平台上，由YARN统一调度实现资源的共享。Storm可以使用任何语言来写topologies。</p>

<p>下面五个特性保证了Storm实时处理的能力：</p>

<ul>
<li><strong>Fast</strong> &ndash; 快，每个节点每秒可以处理百万个100字节的消息</li>
<li><strong>Scalable</strong> &ndash; 可扩展，这没得说</li>
<li><strong>Fault-tolerant</strong> &ndash; 容错，如果workers进程死掉，Storm会自动重启。如果一个节点死掉，会在其它节点上重启workers进程</li>
<li><strong>Reliable</strong> &ndash; 可靠性，Storm确保每个单元数据（tuple）会被处理最少一次，仅仅当消息处理失败才会发生通知</li>
<li><strong>Easy to operate</strong> &ndash; 标准的配置适应于生产环境，一旦部署，Storm很容易操作。</li>
</ul>


<!--more-->


<h1>Storm架构</h1>

<p>一个Storm集群应该包含下面三类节点</p>

<ul>
<li><strong>Nimbus Node</strong> &ndash; master节点，相当于Hadoop集群的JobTracker，负责：Uploads computations for execution（不懂）、在集群中分发代码、负责在集群中启动workers进程、监控计算资源如果需要会重新分配workers进程</li>
<li><strong>ZooKeeper Nodes</strong> &ndash; 负责协调Storm集群，当然也可以由YARN平台来管理</li>
<li><strong>Supervisor Nodes</strong> &ndash; 通过Zookeeper或者YARN与Nimbus节点通信，根据Nimbus返回的消息来启动和停止workers进程</li>
</ul>


<p><img src="/images/storm_0.png"></p>

<p>通过下面5个关键点来理解Storm是如何处理数据的：</p>

<ul>
<li><strong>Tuples</strong> &ndash; 元素的有序列表，例如“4-tuple”可能是（7,1,3,7）</li>
<li><strong>Streams</strong> &ndash; 一个没有边界的tuples序列</li>
<li><strong>Spouts</strong> &ndash; 集群中传输的计算资源（例如 Twitter API）</li>
<li><strong>Bolts</strong> &ndash; 处理输入输出流，可以：启动函数、过滤器、统计或合并数据，或访问数据库</li>
<li><strong>Topologies</strong> &ndash; 由Spouts和Bolts组成的网络结构</li>
</ul>


<p><img src="/images/storm_1.png"></p>

<p>数据由spout输入，由bolt处理，然后存入Hadoop中。</p>

<p>更多请访问<a href="http://zh.hortonworks.com/labs/storm/">这里</a></p>

<p>可以从<a href="http://zh.hortonworks.com/hadoop-tutorial/processing-streaming-data-near-real-time-apache-storm/">这里</a>开始练习。</p>
]]></content>
  </entry>
  
</feed>
